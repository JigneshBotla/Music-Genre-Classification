{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## FCNN without dataslicing"
      ],
      "metadata": {
        "id": "rl8Y8SZ8VQKW"
      },
      "id": "rl8Y8SZ8VQKW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a970506e",
      "metadata": {
        "id": "a970506e"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f670cfcf",
      "metadata": {
        "id": "f670cfcf"
      },
      "outputs": [],
      "source": [
        "sample_rate = 22050\n",
        "n_mels = 130\n",
        "hop_length = 512\n",
        "n_frames = 13\n",
        "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aa3d9a0",
      "metadata": {
        "id": "6aa3d9a0"
      },
      "outputs": [],
      "source": [
        "def augment_audio(audio, sr):\n",
        "\n",
        "    audio_shifted = librosa.effects.pitch_shift(audio, n_steps=np.random.randint(-2, 2), sr=sr)\n",
        "    audio_stretched = librosa.effects.time_stretch(audio, rate=np.random.uniform(0.8, 1.2))\n",
        "    return audio_shifted, audio_stretched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23af3f01",
      "metadata": {
        "id": "23af3f01"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/sample_data/data.json'\n",
        "\n",
        "with open(data_path, \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "# Define X nd y\n",
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"genre_num\"])\n",
        "# Train-validation-test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
        "X_val = X_val[..., np.newaxis]      # Add channel dimension\n",
        "X_test = X_test[..., np.newaxis]    # Add channel dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773e4d26",
      "metadata": {
        "id": "773e4d26"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Dense\n",
        "\n",
        "def build_fcnn(input_shape=(n_mels, n_frames, 1),num_classes=10):\n",
        "    model = Sequential([\n",
        "        #layer 1\n",
        "        Conv2D(32, (3,3), activation='relu',padding='same',input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        #layer 2\n",
        "        Conv2D(64, (3,3), activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        #layer 3\n",
        "        Conv2D(128, (3,3), activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        #layer 4\n",
        "        Conv2D(128, (3,3), activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        GlobalAveragePooling2D(), #Replaces dense layers\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j1gGbpuRVvu",
        "outputId": "ffe7181c-bc64-4199-9e75-b43b80a46c6a"
      },
      "id": "9j1gGbpuRVvu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b78465db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "b78465db",
        "outputId": "c7ffb024-b896-45ee-bfc6-f660739cb9fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m249,920\u001b[0m (976.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249,920</span> (976.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m249,216\u001b[0m (973.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249,216</span> (973.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 5: Build, compile, and summarize model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model = build_fcnn()\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),  # Default Adam LR\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9758ff3",
      "metadata": {
        "id": "e9758ff3"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1ff28f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab1ff28f",
        "outputId": "fb7e523e-18ef-4238-c9b3-cee0d6b869f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - accuracy: 0.2948 - loss: 3.0047 - val_accuracy: 0.2003 - val_loss: 4.5167 - learning_rate: 0.0010\n",
            "Epoch 2/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5747 - loss: 1.3837 - val_accuracy: 0.4764 - val_loss: 1.5750 - learning_rate: 0.0010\n",
            "Epoch 3/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6304 - loss: 1.1379 - val_accuracy: 0.5627 - val_loss: 1.2544 - learning_rate: 0.0010\n",
            "Epoch 4/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6795 - loss: 0.9955 - val_accuracy: 0.5784 - val_loss: 1.3065 - learning_rate: 0.0010\n",
            "Epoch 5/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7102 - loss: 0.8910 - val_accuracy: 0.6271 - val_loss: 1.1354 - learning_rate: 0.0010\n",
            "Epoch 6/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7175 - loss: 0.8308 - val_accuracy: 0.6237 - val_loss: 1.3123 - learning_rate: 0.0010\n",
            "Epoch 7/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7472 - loss: 0.7252 - val_accuracy: 0.6428 - val_loss: 1.1901 - learning_rate: 0.0010\n",
            "Epoch 8/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7674 - loss: 0.6753 - val_accuracy: 0.6609 - val_loss: 1.0791 - learning_rate: 0.0010\n",
            "Epoch 9/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7755 - loss: 0.6346 - val_accuracy: 0.7244 - val_loss: 0.9196 - learning_rate: 0.0010\n",
            "Epoch 10/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7919 - loss: 0.6197 - val_accuracy: 0.7682 - val_loss: 0.7226 - learning_rate: 0.0010\n",
            "Epoch 11/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7951 - loss: 0.6078 - val_accuracy: 0.8050 - val_loss: 0.6277 - learning_rate: 0.0010\n",
            "Epoch 12/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8137 - loss: 0.5566 - val_accuracy: 0.7935 - val_loss: 0.6332 - learning_rate: 0.0010\n",
            "Epoch 13/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8120 - loss: 0.5379 - val_accuracy: 0.8112 - val_loss: 0.5939 - learning_rate: 0.0010\n",
            "Epoch 14/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8327 - loss: 0.5136 - val_accuracy: 0.7554 - val_loss: 0.7585 - learning_rate: 0.0010\n",
            "Epoch 15/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8280 - loss: 0.4935 - val_accuracy: 0.7992 - val_loss: 0.6886 - learning_rate: 0.0010\n",
            "Epoch 16/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 0.4832 - val_accuracy: 0.7935 - val_loss: 0.6300 - learning_rate: 0.0010\n",
            "Epoch 17/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8414 - loss: 0.4474 - val_accuracy: 0.7916 - val_loss: 0.7002 - learning_rate: 0.0010\n",
            "Epoch 18/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.3817 - val_accuracy: 0.7997 - val_loss: 0.6247 - learning_rate: 0.0010\n",
            "Epoch 19/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8531 - loss: 0.3955 - val_accuracy: 0.8302 - val_loss: 0.5211 - learning_rate: 0.0010\n",
            "Epoch 20/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8630 - loss: 0.3800 - val_accuracy: 0.8426 - val_loss: 0.5143 - learning_rate: 0.0010\n",
            "Epoch 21/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.3720 - val_accuracy: 0.8417 - val_loss: 0.5385 - learning_rate: 0.0010\n",
            "Epoch 22/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8718 - loss: 0.3720 - val_accuracy: 0.8288 - val_loss: 0.5365 - learning_rate: 0.0010\n",
            "Epoch 23/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8647 - loss: 0.3899 - val_accuracy: 0.8355 - val_loss: 0.5114 - learning_rate: 0.0010\n",
            "Epoch 24/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8793 - loss: 0.3371 - val_accuracy: 0.8236 - val_loss: 0.5580 - learning_rate: 0.0010\n",
            "Epoch 25/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8809 - loss: 0.3344 - val_accuracy: 0.8398 - val_loss: 0.5027 - learning_rate: 0.0010\n",
            "Epoch 26/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8971 - loss: 0.2974 - val_accuracy: 0.8293 - val_loss: 0.5482 - learning_rate: 0.0010\n",
            "Epoch 27/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8823 - loss: 0.3253 - val_accuracy: 0.8412 - val_loss: 0.5317 - learning_rate: 0.0010\n",
            "Epoch 28/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8925 - loss: 0.3184 - val_accuracy: 0.8188 - val_loss: 0.6131 - learning_rate: 0.0010\n",
            "Epoch 29/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8842 - loss: 0.3136 - val_accuracy: 0.8464 - val_loss: 0.5099 - learning_rate: 0.0010\n",
            "Epoch 30/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8915 - loss: 0.3019 - val_accuracy: 0.8412 - val_loss: 0.5333 - learning_rate: 0.0010\n",
            "Epoch 31/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9084 - loss: 0.2747 - val_accuracy: 0.8584 - val_loss: 0.4945 - learning_rate: 0.0010\n",
            "Epoch 32/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2618 - val_accuracy: 0.8569 - val_loss: 0.4735 - learning_rate: 0.0010\n",
            "Epoch 33/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2331 - val_accuracy: 0.8312 - val_loss: 0.6009 - learning_rate: 0.0010\n",
            "Epoch 34/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9138 - loss: 0.2453 - val_accuracy: 0.8274 - val_loss: 0.5670 - learning_rate: 0.0010\n",
            "Epoch 35/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9042 - loss: 0.2715 - val_accuracy: 0.8503 - val_loss: 0.5144 - learning_rate: 0.0010\n",
            "Epoch 36/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9146 - loss: 0.2352 - val_accuracy: 0.8522 - val_loss: 0.5179 - learning_rate: 0.0010\n",
            "Epoch 37/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9258 - loss: 0.2212 - val_accuracy: 0.8798 - val_loss: 0.4254 - learning_rate: 0.0010\n",
            "Epoch 38/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9205 - loss: 0.2390 - val_accuracy: 0.8522 - val_loss: 0.5102 - learning_rate: 0.0010\n",
            "Epoch 39/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9209 - loss: 0.2365 - val_accuracy: 0.8670 - val_loss: 0.4571 - learning_rate: 0.0010\n",
            "Epoch 40/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.2197 - val_accuracy: 0.8650 - val_loss: 0.4831 - learning_rate: 0.0010\n",
            "Epoch 41/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9311 - loss: 0.2051 - val_accuracy: 0.8641 - val_loss: 0.4595 - learning_rate: 0.0010\n",
            "Epoch 42/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9341 - loss: 0.1905 - val_accuracy: 0.8693 - val_loss: 0.4645 - learning_rate: 0.0010\n",
            "Epoch 43/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9257 - loss: 0.2069 - val_accuracy: 0.8574 - val_loss: 0.4984 - learning_rate: 0.0010\n",
            "Epoch 44/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9234 - loss: 0.2188 - val_accuracy: 0.8636 - val_loss: 0.4728 - learning_rate: 0.0010\n",
            "Epoch 45/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.1904 - val_accuracy: 0.8832 - val_loss: 0.4161 - learning_rate: 0.0010\n",
            "Epoch 46/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9338 - loss: 0.2052 - val_accuracy: 0.8827 - val_loss: 0.4058 - learning_rate: 0.0010\n",
            "Epoch 47/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9380 - loss: 0.1837 - val_accuracy: 0.8808 - val_loss: 0.4246 - learning_rate: 0.0010\n",
            "Epoch 48/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9323 - loss: 0.1939 - val_accuracy: 0.8689 - val_loss: 0.4777 - learning_rate: 0.0010\n",
            "Epoch 49/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9356 - loss: 0.1806 - val_accuracy: 0.8898 - val_loss: 0.3650 - learning_rate: 0.0010\n",
            "Epoch 50/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9361 - loss: 0.1800 - val_accuracy: 0.8832 - val_loss: 0.3940 - learning_rate: 0.0010\n",
            "Epoch 51/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9260 - loss: 0.1948 - val_accuracy: 0.8932 - val_loss: 0.3758 - learning_rate: 0.0010\n",
            "Epoch 52/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9361 - loss: 0.1747 - val_accuracy: 0.8898 - val_loss: 0.4117 - learning_rate: 0.0010\n",
            "Epoch 53/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.1629 - val_accuracy: 0.8631 - val_loss: 0.4902 - learning_rate: 0.0010\n",
            "Epoch 54/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9325 - loss: 0.1875 - val_accuracy: 0.8884 - val_loss: 0.3947 - learning_rate: 0.0010\n",
            "Epoch 55/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.1562 - val_accuracy: 0.8846 - val_loss: 0.4440 - learning_rate: 0.0010\n",
            "Epoch 56/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.1542 - val_accuracy: 0.8817 - val_loss: 0.4534 - learning_rate: 0.0010\n",
            "Epoch 57/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9427 - loss: 0.1692 - val_accuracy: 0.8856 - val_loss: 0.3950 - learning_rate: 0.0010\n",
            "Epoch 58/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9368 - loss: 0.1680 - val_accuracy: 0.8903 - val_loss: 0.4128 - learning_rate: 0.0010\n",
            "Epoch 59/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.1489 - val_accuracy: 0.8703 - val_loss: 0.4701 - learning_rate: 0.0010\n",
            "Epoch 60/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9570 - loss: 0.1281 - val_accuracy: 0.8908 - val_loss: 0.3776 - learning_rate: 5.0000e-04\n",
            "Epoch 61/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9612 - loss: 0.1101 - val_accuracy: 0.9041 - val_loss: 0.3473 - learning_rate: 5.0000e-04\n",
            "Epoch 62/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9656 - loss: 0.1025 - val_accuracy: 0.9032 - val_loss: 0.3653 - learning_rate: 5.0000e-04\n",
            "Epoch 63/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.1185 - val_accuracy: 0.8984 - val_loss: 0.3776 - learning_rate: 5.0000e-04\n",
            "Epoch 64/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9587 - loss: 0.1129 - val_accuracy: 0.8989 - val_loss: 0.3928 - learning_rate: 5.0000e-04\n",
            "Epoch 65/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9587 - loss: 0.1171 - val_accuracy: 0.8970 - val_loss: 0.4014 - learning_rate: 5.0000e-04\n",
            "Epoch 66/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.0931 - val_accuracy: 0.8960 - val_loss: 0.3941 - learning_rate: 5.0000e-04\n",
            "Epoch 67/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9653 - loss: 0.1026 - val_accuracy: 0.8965 - val_loss: 0.3591 - learning_rate: 5.0000e-04\n",
            "Epoch 68/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0918 - val_accuracy: 0.8946 - val_loss: 0.3853 - learning_rate: 5.0000e-04\n",
            "Epoch 69/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9670 - loss: 0.0937 - val_accuracy: 0.9027 - val_loss: 0.3538 - learning_rate: 5.0000e-04\n",
            "Epoch 70/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9649 - loss: 0.0958 - val_accuracy: 0.8908 - val_loss: 0.3948 - learning_rate: 5.0000e-04\n",
            "Epoch 71/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9650 - loss: 0.1042 - val_accuracy: 0.8999 - val_loss: 0.3718 - learning_rate: 5.0000e-04\n",
            "Epoch 72/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9710 - loss: 0.0854 - val_accuracy: 0.9113 - val_loss: 0.3301 - learning_rate: 2.5000e-04\n",
            "Epoch 73/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9713 - loss: 0.0794 - val_accuracy: 0.9099 - val_loss: 0.3383 - learning_rate: 2.5000e-04\n",
            "Epoch 74/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9682 - loss: 0.0923 - val_accuracy: 0.9156 - val_loss: 0.3340 - learning_rate: 2.5000e-04\n",
            "Epoch 75/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9714 - loss: 0.0747 - val_accuracy: 0.8960 - val_loss: 0.3804 - learning_rate: 2.5000e-04\n",
            "Epoch 76/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0720 - val_accuracy: 0.9103 - val_loss: 0.3306 - learning_rate: 2.5000e-04\n",
            "Epoch 77/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.0997 - val_accuracy: 0.9094 - val_loss: 0.3526 - learning_rate: 2.5000e-04\n",
            "Epoch 78/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9751 - loss: 0.0783 - val_accuracy: 0.9156 - val_loss: 0.3341 - learning_rate: 2.5000e-04\n",
            "Epoch 79/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0726 - val_accuracy: 0.9094 - val_loss: 0.3459 - learning_rate: 2.5000e-04\n",
            "Epoch 80/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0696 - val_accuracy: 0.9089 - val_loss: 0.3611 - learning_rate: 2.5000e-04\n",
            "Epoch 81/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9717 - loss: 0.0809 - val_accuracy: 0.9118 - val_loss: 0.3530 - learning_rate: 2.5000e-04\n",
            "Epoch 82/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0785 - val_accuracy: 0.9080 - val_loss: 0.3710 - learning_rate: 2.5000e-04\n",
            "Epoch 83/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9656 - loss: 0.0865 - val_accuracy: 0.9137 - val_loss: 0.3397 - learning_rate: 1.2500e-04\n",
            "Epoch 84/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9774 - loss: 0.0714 - val_accuracy: 0.9142 - val_loss: 0.3407 - learning_rate: 1.2500e-04\n",
            "Epoch 85/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9753 - loss: 0.0756 - val_accuracy: 0.9113 - val_loss: 0.3593 - learning_rate: 1.2500e-04\n",
            "Epoch 86/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9812 - loss: 0.0614 - val_accuracy: 0.9123 - val_loss: 0.3492 - learning_rate: 1.2500e-04\n",
            "Epoch 87/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0632 - val_accuracy: 0.9123 - val_loss: 0.3490 - learning_rate: 1.2500e-04\n",
            "Epoch 88/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0618 - val_accuracy: 0.9175 - val_loss: 0.3207 - learning_rate: 1.2500e-04\n",
            "Epoch 89/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9816 - loss: 0.0579 - val_accuracy: 0.9151 - val_loss: 0.3414 - learning_rate: 1.2500e-04\n",
            "Epoch 90/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9766 - loss: 0.0602 - val_accuracy: 0.9170 - val_loss: 0.3274 - learning_rate: 1.2500e-04\n",
            "Epoch 91/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.0605 - val_accuracy: 0.9132 - val_loss: 0.3442 - learning_rate: 1.2500e-04\n",
            "Epoch 92/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.0562 - val_accuracy: 0.9213 - val_loss: 0.3123 - learning_rate: 1.2500e-04\n",
            "Epoch 93/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9805 - loss: 0.0556 - val_accuracy: 0.9161 - val_loss: 0.3210 - learning_rate: 1.2500e-04\n",
            "Epoch 94/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0575 - val_accuracy: 0.9165 - val_loss: 0.3224 - learning_rate: 1.2500e-04\n",
            "Epoch 95/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0664 - val_accuracy: 0.9175 - val_loss: 0.3281 - learning_rate: 1.2500e-04\n",
            "Epoch 96/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0583 - val_accuracy: 0.9151 - val_loss: 0.3364 - learning_rate: 1.2500e-04\n",
            "Epoch 97/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9784 - loss: 0.0638 - val_accuracy: 0.9185 - val_loss: 0.3441 - learning_rate: 1.2500e-04\n",
            "Epoch 98/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0669 - val_accuracy: 0.9123 - val_loss: 0.3536 - learning_rate: 1.2500e-04\n",
            "Epoch 99/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9816 - loss: 0.0559 - val_accuracy: 0.9151 - val_loss: 0.3463 - learning_rate: 1.2500e-04\n",
            "Epoch 100/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0731 - val_accuracy: 0.9127 - val_loss: 0.3368 - learning_rate: 1.2500e-04\n",
            "Epoch 101/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9788 - loss: 0.0633 - val_accuracy: 0.9123 - val_loss: 0.3432 - learning_rate: 1.2500e-04\n",
            "Epoch 102/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9697 - loss: 0.0736 - val_accuracy: 0.9142 - val_loss: 0.3389 - learning_rate: 1.2500e-04\n",
            "Epoch 103/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.0688 - val_accuracy: 0.9161 - val_loss: 0.3346 - learning_rate: 6.2500e-05\n",
            "Epoch 104/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9867 - loss: 0.0508 - val_accuracy: 0.9170 - val_loss: 0.3305 - learning_rate: 6.2500e-05\n",
            "Epoch 105/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0503 - val_accuracy: 0.9151 - val_loss: 0.3273 - learning_rate: 6.2500e-05\n",
            "Epoch 106/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9791 - loss: 0.0611 - val_accuracy: 0.9170 - val_loss: 0.3320 - learning_rate: 6.2500e-05\n",
            "Epoch 107/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.0627 - val_accuracy: 0.9123 - val_loss: 0.3329 - learning_rate: 6.2500e-05\n",
            "Epoch 108/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.0476 - val_accuracy: 0.9170 - val_loss: 0.3285 - learning_rate: 6.2500e-05\n",
            "Epoch 109/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0591 - val_accuracy: 0.9165 - val_loss: 0.3423 - learning_rate: 6.2500e-05\n",
            "Epoch 110/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9825 - loss: 0.0531 - val_accuracy: 0.9189 - val_loss: 0.3314 - learning_rate: 6.2500e-05\n",
            "Epoch 111/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9760 - loss: 0.0620 - val_accuracy: 0.9146 - val_loss: 0.3362 - learning_rate: 6.2500e-05\n",
            "Epoch 112/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.0487 - val_accuracy: 0.9199 - val_loss: 0.3244 - learning_rate: 6.2500e-05\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9220 - loss: 0.3034\n",
            "Test_accuracy : 0.9212\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "\n",
        "# Step 6: Train model on T4 GPU\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=250,\n",
        "                    batch_size=64,\n",
        "                    callbacks=[early_stopping,lr_scheduler])\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test_accuracy : {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5b07d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee5b07d3",
        "outputId": "0298a364-26d1-42fc-aacb-39cfc3755331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('/content/sample_data/fcnn_melspec_gtzan.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FCNN with data slicing"
      ],
      "metadata": {
        "id": "rWocEPYyVgRN"
      },
      "id": "rWocEPYyVgRN"
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Enable mixed precision for faster GPU training\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Parameters\n",
        "sample_rate = 22050\n",
        "n_mels = 130\n",
        "hop_length = 512\n",
        "segment_length = 3  # 3-second clips\n",
        "n_frames = int((segment_length * sample_rate / hop_length) + 1)  # ~129 for 3 seconds\n",
        "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "batch_size = 16\n",
        "data_path = '/content/sample_data/data.json'  # Update with your GTZAN dataset path\n",
        "\n",
        "# Function to split audio into 3-second segments\n",
        "def split_audio(audio, sr, segment_length=3):\n",
        "    samples_per_segment = int(segment_length * sr)\n",
        "    segments = [audio[i:i + samples_per_segment] for i in range(0, len(audio), samples_per_segment)]\n",
        "    return segments\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading and preprocessing data...\")\n",
        "\n",
        "with open(data_path, \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "# Define X nd y\n",
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"genre_num\"])\n",
        "# Train-validation-test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
        "X_val = X_val[..., np.newaxis]      # Add channel dimension\n",
        "X_test = X_test[..., np.newaxis]    # Add channel dimension\n",
        "\n",
        "\n",
        "# Create tf.data datasets for efficient loading\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build simpler FCNN\n",
        "def build_fcnn(input_shape=(n_mels, n_frames, 1), num_classes=10):\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax', dtype='float32')  # Mixed precision output\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Build and compile model\n",
        "model = build_fcnn()\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),  # Default Adam LR\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train with early stopping\n",
        "# Step 6: Train model on T4 GPU\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
        "\n",
        "print(\"Training model...\")\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=250,\n",
        "    callbacks=[early_stopping,lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Plot training/validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H-InjY9VVf6V",
        "outputId": "b16f1d88-669a-4246-96ba-349d01ef2741"
      },
      "id": "H-InjY9VVf6V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,394\u001b[0m (95.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,394</span> (95.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,170\u001b[0m (94.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,170</span> (94.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Epoch 1/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.2161 - loss: 2.1329 - val_accuracy: 0.2613 - val_loss: 1.9176 - learning_rate: 1.0000e-04\n",
            "Epoch 2/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.3304 - loss: 1.8551 - val_accuracy: 0.3019 - val_loss: 1.8205 - learning_rate: 1.0000e-04\n",
            "Epoch 3/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3853 - loss: 1.7062 - val_accuracy: 0.3591 - val_loss: 1.7123 - learning_rate: 1.0000e-04\n",
            "Epoch 4/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4435 - loss: 1.5469 - val_accuracy: 0.4192 - val_loss: 1.5391 - learning_rate: 1.0000e-04\n",
            "Epoch 5/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4582 - loss: 1.4912 - val_accuracy: 0.4616 - val_loss: 1.4501 - learning_rate: 1.0000e-04\n",
            "Epoch 6/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4841 - loss: 1.4424 - val_accuracy: 0.4678 - val_loss: 1.4161 - learning_rate: 1.0000e-04\n",
            "Epoch 7/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5025 - loss: 1.3859 - val_accuracy: 0.4826 - val_loss: 1.4003 - learning_rate: 1.0000e-04\n",
            "Epoch 8/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5192 - loss: 1.3546 - val_accuracy: 0.4945 - val_loss: 1.3572 - learning_rate: 1.0000e-04\n",
            "Epoch 9/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5216 - loss: 1.3428 - val_accuracy: 0.5227 - val_loss: 1.3121 - learning_rate: 1.0000e-04\n",
            "Epoch 10/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5237 - loss: 1.3310 - val_accuracy: 0.5150 - val_loss: 1.2816 - learning_rate: 1.0000e-04\n",
            "Epoch 11/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5318 - loss: 1.3041 - val_accuracy: 0.5250 - val_loss: 1.3007 - learning_rate: 1.0000e-04\n",
            "Epoch 12/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5453 - loss: 1.2823 - val_accuracy: 0.5312 - val_loss: 1.2586 - learning_rate: 1.0000e-04\n",
            "Epoch 13/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5597 - loss: 1.2572 - val_accuracy: 0.5265 - val_loss: 1.2537 - learning_rate: 1.0000e-04\n",
            "Epoch 14/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5632 - loss: 1.2447 - val_accuracy: 0.5422 - val_loss: 1.2449 - learning_rate: 1.0000e-04\n",
            "Epoch 15/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5636 - loss: 1.2409 - val_accuracy: 0.5427 - val_loss: 1.2264 - learning_rate: 1.0000e-04\n",
            "Epoch 16/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5693 - loss: 1.2197 - val_accuracy: 0.5446 - val_loss: 1.2075 - learning_rate: 1.0000e-04\n",
            "Epoch 17/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5680 - loss: 1.1954 - val_accuracy: 0.5565 - val_loss: 1.1907 - learning_rate: 1.0000e-04\n",
            "Epoch 18/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5924 - loss: 1.1877 - val_accuracy: 0.5646 - val_loss: 1.1796 - learning_rate: 1.0000e-04\n",
            "Epoch 19/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6029 - loss: 1.1466 - val_accuracy: 0.5818 - val_loss: 1.1440 - learning_rate: 1.0000e-04\n",
            "Epoch 20/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5822 - loss: 1.1737 - val_accuracy: 0.5932 - val_loss: 1.1234 - learning_rate: 1.0000e-04\n",
            "Epoch 21/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6005 - loss: 1.1352 - val_accuracy: 0.5932 - val_loss: 1.1256 - learning_rate: 1.0000e-04\n",
            "Epoch 22/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6015 - loss: 1.1309 - val_accuracy: 0.5894 - val_loss: 1.1283 - learning_rate: 1.0000e-04\n",
            "Epoch 23/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6174 - loss: 1.1177 - val_accuracy: 0.6099 - val_loss: 1.0968 - learning_rate: 1.0000e-04\n",
            "Epoch 24/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6065 - loss: 1.1388 - val_accuracy: 0.5846 - val_loss: 1.1222 - learning_rate: 1.0000e-04\n",
            "Epoch 25/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6168 - loss: 1.1082 - val_accuracy: 0.5746 - val_loss: 1.1416 - learning_rate: 1.0000e-04\n",
            "Epoch 26/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6188 - loss: 1.1125 - val_accuracy: 0.6061 - val_loss: 1.0852 - learning_rate: 1.0000e-04\n",
            "Epoch 27/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6168 - loss: 1.1113 - val_accuracy: 0.6190 - val_loss: 1.0555 - learning_rate: 1.0000e-04\n",
            "Epoch 28/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6263 - loss: 1.0932 - val_accuracy: 0.6090 - val_loss: 1.0731 - learning_rate: 1.0000e-04\n",
            "Epoch 29/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6248 - loss: 1.0740 - val_accuracy: 0.6032 - val_loss: 1.0730 - learning_rate: 1.0000e-04\n",
            "Epoch 30/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6310 - loss: 1.0495 - val_accuracy: 0.6319 - val_loss: 1.0241 - learning_rate: 1.0000e-04\n",
            "Epoch 31/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6350 - loss: 1.0428 - val_accuracy: 0.6166 - val_loss: 1.0508 - learning_rate: 1.0000e-04\n",
            "Epoch 32/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6403 - loss: 1.0451 - val_accuracy: 0.6261 - val_loss: 1.0380 - learning_rate: 1.0000e-04\n",
            "Epoch 33/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6411 - loss: 1.0295 - val_accuracy: 0.6338 - val_loss: 1.0068 - learning_rate: 1.0000e-04\n",
            "Epoch 34/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6411 - loss: 1.0101 - val_accuracy: 0.6361 - val_loss: 1.0161 - learning_rate: 1.0000e-04\n",
            "Epoch 35/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6543 - loss: 1.0195 - val_accuracy: 0.6443 - val_loss: 0.9710 - learning_rate: 1.0000e-04\n",
            "Epoch 36/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6446 - loss: 1.0268 - val_accuracy: 0.6447 - val_loss: 0.9918 - learning_rate: 1.0000e-04\n",
            "Epoch 37/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6546 - loss: 1.0160 - val_accuracy: 0.6433 - val_loss: 0.9931 - learning_rate: 1.0000e-04\n",
            "Epoch 38/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6660 - loss: 0.9879 - val_accuracy: 0.6667 - val_loss: 0.9329 - learning_rate: 1.0000e-04\n",
            "Epoch 39/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6434 - loss: 1.0307 - val_accuracy: 0.6481 - val_loss: 0.9865 - learning_rate: 1.0000e-04\n",
            "Epoch 40/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6607 - loss: 1.0026 - val_accuracy: 0.6485 - val_loss: 0.9744 - learning_rate: 1.0000e-04\n",
            "Epoch 41/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6701 - loss: 0.9723 - val_accuracy: 0.6729 - val_loss: 0.9133 - learning_rate: 1.0000e-04\n",
            "Epoch 42/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6643 - loss: 0.9674 - val_accuracy: 0.6776 - val_loss: 0.9373 - learning_rate: 1.0000e-04\n",
            "Epoch 43/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6659 - loss: 0.9653 - val_accuracy: 0.6671 - val_loss: 0.9368 - learning_rate: 1.0000e-04\n",
            "Epoch 44/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6764 - loss: 0.9677 - val_accuracy: 0.6705 - val_loss: 0.9155 - learning_rate: 1.0000e-04\n",
            "Epoch 45/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6786 - loss: 0.9545 - val_accuracy: 0.6857 - val_loss: 0.8927 - learning_rate: 1.0000e-04\n",
            "Epoch 46/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6732 - loss: 0.9565 - val_accuracy: 0.6814 - val_loss: 0.8940 - learning_rate: 1.0000e-04\n",
            "Epoch 47/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6707 - loss: 0.9501 - val_accuracy: 0.6757 - val_loss: 0.9168 - learning_rate: 1.0000e-04\n",
            "Epoch 48/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6790 - loss: 0.9403 - val_accuracy: 0.6748 - val_loss: 0.9183 - learning_rate: 1.0000e-04\n",
            "Epoch 49/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6816 - loss: 0.9216 - val_accuracy: 0.6748 - val_loss: 0.9150 - learning_rate: 1.0000e-04\n",
            "Epoch 50/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6706 - loss: 0.9425 - val_accuracy: 0.6910 - val_loss: 0.8903 - learning_rate: 1.0000e-04\n",
            "Epoch 51/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6947 - loss: 0.9183 - val_accuracy: 0.6838 - val_loss: 0.8937 - learning_rate: 1.0000e-04\n",
            "Epoch 52/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6772 - loss: 0.9319 - val_accuracy: 0.6967 - val_loss: 0.8582 - learning_rate: 1.0000e-04\n",
            "Epoch 53/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6821 - loss: 0.9363 - val_accuracy: 0.6996 - val_loss: 0.8592 - learning_rate: 1.0000e-04\n",
            "Epoch 54/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6911 - loss: 0.9236 - val_accuracy: 0.7029 - val_loss: 0.8568 - learning_rate: 1.0000e-04\n",
            "Epoch 55/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6948 - loss: 0.9101 - val_accuracy: 0.7177 - val_loss: 0.8274 - learning_rate: 1.0000e-04\n",
            "Epoch 56/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6885 - loss: 0.9121 - val_accuracy: 0.6872 - val_loss: 0.8860 - learning_rate: 1.0000e-04\n",
            "Epoch 57/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6931 - loss: 0.9017 - val_accuracy: 0.6824 - val_loss: 0.9015 - learning_rate: 1.0000e-04\n",
            "Epoch 58/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6945 - loss: 0.9079 - val_accuracy: 0.7062 - val_loss: 0.8395 - learning_rate: 1.0000e-04\n",
            "Epoch 59/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6955 - loss: 0.8839 - val_accuracy: 0.6953 - val_loss: 0.8678 - learning_rate: 1.0000e-04\n",
            "Epoch 60/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6960 - loss: 0.8920 - val_accuracy: 0.7148 - val_loss: 0.8286 - learning_rate: 1.0000e-04\n",
            "Epoch 61/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 0.9192 - val_accuracy: 0.6991 - val_loss: 0.8694 - learning_rate: 1.0000e-04\n",
            "Epoch 62/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6957 - loss: 0.8753 - val_accuracy: 0.7015 - val_loss: 0.8408 - learning_rate: 1.0000e-04\n",
            "Epoch 63/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6998 - loss: 0.8687 - val_accuracy: 0.7005 - val_loss: 0.8677 - learning_rate: 1.0000e-04\n",
            "Epoch 64/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7135 - loss: 0.8399 - val_accuracy: 0.6915 - val_loss: 0.8746 - learning_rate: 1.0000e-04\n",
            "Epoch 65/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6924 - loss: 0.8849 - val_accuracy: 0.7148 - val_loss: 0.8361 - learning_rate: 1.0000e-04\n",
            "Epoch 66/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6938 - loss: 0.8817 - val_accuracy: 0.7210 - val_loss: 0.8154 - learning_rate: 5.0000e-05\n",
            "Epoch 67/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7069 - loss: 0.8699 - val_accuracy: 0.7196 - val_loss: 0.8154 - learning_rate: 5.0000e-05\n",
            "Epoch 68/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.8505 - val_accuracy: 0.7177 - val_loss: 0.8061 - learning_rate: 5.0000e-05\n",
            "Epoch 69/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7136 - loss: 0.8262 - val_accuracy: 0.7215 - val_loss: 0.8089 - learning_rate: 5.0000e-05\n",
            "Epoch 70/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6979 - loss: 0.8598 - val_accuracy: 0.7248 - val_loss: 0.8021 - learning_rate: 5.0000e-05\n",
            "Epoch 71/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7155 - loss: 0.8511 - val_accuracy: 0.7196 - val_loss: 0.8116 - learning_rate: 5.0000e-05\n",
            "Epoch 72/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7001 - loss: 0.8697 - val_accuracy: 0.7220 - val_loss: 0.8062 - learning_rate: 5.0000e-05\n",
            "Epoch 73/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7100 - loss: 0.8643 - val_accuracy: 0.7248 - val_loss: 0.7986 - learning_rate: 5.0000e-05\n",
            "Epoch 74/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6999 - loss: 0.8659 - val_accuracy: 0.7239 - val_loss: 0.8045 - learning_rate: 5.0000e-05\n",
            "Epoch 75/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7142 - loss: 0.8280 - val_accuracy: 0.7206 - val_loss: 0.8146 - learning_rate: 5.0000e-05\n",
            "Epoch 76/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.8461 - val_accuracy: 0.7220 - val_loss: 0.8060 - learning_rate: 5.0000e-05\n",
            "Epoch 77/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.8267 - val_accuracy: 0.7253 - val_loss: 0.8005 - learning_rate: 5.0000e-05\n",
            "Epoch 78/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.8250 - val_accuracy: 0.7215 - val_loss: 0.8099 - learning_rate: 5.0000e-05\n",
            "Epoch 79/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7008 - loss: 0.8521 - val_accuracy: 0.7191 - val_loss: 0.8183 - learning_rate: 5.0000e-05\n",
            "Epoch 80/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7135 - loss: 0.8187 - val_accuracy: 0.7196 - val_loss: 0.8035 - learning_rate: 5.0000e-05\n",
            "Epoch 81/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7119 - loss: 0.8516 - val_accuracy: 0.7234 - val_loss: 0.8119 - learning_rate: 5.0000e-05\n",
            "Epoch 82/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7255 - loss: 0.7956 - val_accuracy: 0.7325 - val_loss: 0.7801 - learning_rate: 5.0000e-05\n",
            "Epoch 83/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7254 - loss: 0.8197 - val_accuracy: 0.7191 - val_loss: 0.8091 - learning_rate: 5.0000e-05\n",
            "Epoch 84/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7103 - loss: 0.8405 - val_accuracy: 0.7353 - val_loss: 0.7830 - learning_rate: 5.0000e-05\n",
            "Epoch 85/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7241 - loss: 0.8078 - val_accuracy: 0.7315 - val_loss: 0.7836 - learning_rate: 5.0000e-05\n",
            "Epoch 86/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7243 - loss: 0.8145 - val_accuracy: 0.7334 - val_loss: 0.7818 - learning_rate: 5.0000e-05\n",
            "Epoch 87/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7253 - loss: 0.8072 - val_accuracy: 0.7296 - val_loss: 0.7833 - learning_rate: 5.0000e-05\n",
            "Epoch 88/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7218 - loss: 0.8088 - val_accuracy: 0.7263 - val_loss: 0.7934 - learning_rate: 5.0000e-05\n",
            "Epoch 89/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7152 - loss: 0.8249 - val_accuracy: 0.7315 - val_loss: 0.7769 - learning_rate: 5.0000e-05\n",
            "Epoch 90/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7265 - loss: 0.8106 - val_accuracy: 0.7353 - val_loss: 0.7746 - learning_rate: 5.0000e-05\n",
            "Epoch 91/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7101 - loss: 0.8258 - val_accuracy: 0.7454 - val_loss: 0.7524 - learning_rate: 5.0000e-05\n",
            "Epoch 92/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7335 - loss: 0.7903 - val_accuracy: 0.7301 - val_loss: 0.7837 - learning_rate: 5.0000e-05\n",
            "Epoch 93/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7176 - loss: 0.8189 - val_accuracy: 0.7315 - val_loss: 0.7939 - learning_rate: 5.0000e-05\n",
            "Epoch 94/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7042 - loss: 0.8300 - val_accuracy: 0.7296 - val_loss: 0.7971 - learning_rate: 5.0000e-05\n",
            "Epoch 95/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7204 - loss: 0.8301 - val_accuracy: 0.7339 - val_loss: 0.7661 - learning_rate: 5.0000e-05\n",
            "Epoch 96/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7250 - loss: 0.8054 - val_accuracy: 0.7339 - val_loss: 0.7725 - learning_rate: 5.0000e-05\n",
            "Epoch 97/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7277 - loss: 0.8224 - val_accuracy: 0.7368 - val_loss: 0.7671 - learning_rate: 5.0000e-05\n",
            "Epoch 98/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7407 - loss: 0.7837 - val_accuracy: 0.7406 - val_loss: 0.7615 - learning_rate: 5.0000e-05\n",
            "Epoch 99/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.7954 - val_accuracy: 0.7306 - val_loss: 0.7723 - learning_rate: 5.0000e-05\n",
            "Epoch 100/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.7993 - val_accuracy: 0.7406 - val_loss: 0.7626 - learning_rate: 5.0000e-05\n",
            "Epoch 101/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7244 - loss: 0.7876 - val_accuracy: 0.7377 - val_loss: 0.7560 - learning_rate: 5.0000e-05\n",
            "Epoch 102/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.7813 - val_accuracy: 0.7401 - val_loss: 0.7596 - learning_rate: 2.5000e-05\n",
            "Epoch 103/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7360 - loss: 0.7713 - val_accuracy: 0.7530 - val_loss: 0.7394 - learning_rate: 2.5000e-05\n",
            "Epoch 104/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7255 - loss: 0.8104 - val_accuracy: 0.7496 - val_loss: 0.7447 - learning_rate: 2.5000e-05\n",
            "Epoch 105/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7311 - loss: 0.7861 - val_accuracy: 0.7454 - val_loss: 0.7511 - learning_rate: 2.5000e-05\n",
            "Epoch 106/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7304 - loss: 0.7836 - val_accuracy: 0.7482 - val_loss: 0.7453 - learning_rate: 2.5000e-05\n",
            "Epoch 107/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7406 - loss: 0.7709 - val_accuracy: 0.7487 - val_loss: 0.7397 - learning_rate: 2.5000e-05\n",
            "Epoch 108/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7401 - loss: 0.7645 - val_accuracy: 0.7496 - val_loss: 0.7425 - learning_rate: 2.5000e-05\n",
            "Epoch 109/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7452 - loss: 0.7530 - val_accuracy: 0.7515 - val_loss: 0.7394 - learning_rate: 2.5000e-05\n",
            "Epoch 110/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7277 - loss: 0.7884 - val_accuracy: 0.7477 - val_loss: 0.7369 - learning_rate: 2.5000e-05\n",
            "Epoch 111/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7275 - loss: 0.8039 - val_accuracy: 0.7496 - val_loss: 0.7507 - learning_rate: 2.5000e-05\n",
            "Epoch 112/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7268 - loss: 0.8040 - val_accuracy: 0.7511 - val_loss: 0.7419 - learning_rate: 2.5000e-05\n",
            "Epoch 113/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7219 - loss: 0.7961 - val_accuracy: 0.7487 - val_loss: 0.7440 - learning_rate: 2.5000e-05\n",
            "Epoch 114/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.7968 - val_accuracy: 0.7501 - val_loss: 0.7426 - learning_rate: 2.5000e-05\n",
            "Epoch 115/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7453 - loss: 0.7657 - val_accuracy: 0.7525 - val_loss: 0.7400 - learning_rate: 2.5000e-05\n",
            "Epoch 116/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7296 - loss: 0.7962 - val_accuracy: 0.7473 - val_loss: 0.7528 - learning_rate: 2.5000e-05\n",
            "Epoch 117/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7341 - loss: 0.7842 - val_accuracy: 0.7530 - val_loss: 0.7340 - learning_rate: 2.5000e-05\n",
            "Epoch 118/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7378 - loss: 0.7762 - val_accuracy: 0.7511 - val_loss: 0.7388 - learning_rate: 2.5000e-05\n",
            "Epoch 119/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7322 - loss: 0.7685 - val_accuracy: 0.7601 - val_loss: 0.7271 - learning_rate: 2.5000e-05\n",
            "Epoch 120/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.7625 - val_accuracy: 0.7558 - val_loss: 0.7298 - learning_rate: 2.5000e-05\n",
            "Epoch 121/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7245 - loss: 0.7860 - val_accuracy: 0.7511 - val_loss: 0.7413 - learning_rate: 2.5000e-05\n",
            "Epoch 122/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.7729 - val_accuracy: 0.7563 - val_loss: 0.7336 - learning_rate: 2.5000e-05\n",
            "Epoch 123/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7264 - loss: 0.8019 - val_accuracy: 0.7568 - val_loss: 0.7285 - learning_rate: 2.5000e-05\n",
            "Epoch 124/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7329 - loss: 0.7832 - val_accuracy: 0.7525 - val_loss: 0.7412 - learning_rate: 2.5000e-05\n",
            "Epoch 125/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7442 - loss: 0.7847 - val_accuracy: 0.7554 - val_loss: 0.7315 - learning_rate: 2.5000e-05\n",
            "Epoch 126/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.7938 - val_accuracy: 0.7539 - val_loss: 0.7341 - learning_rate: 2.5000e-05\n",
            "Epoch 127/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.7518 - val_accuracy: 0.7577 - val_loss: 0.7322 - learning_rate: 2.5000e-05\n",
            "Epoch 128/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7416 - loss: 0.7627 - val_accuracy: 0.7549 - val_loss: 0.7307 - learning_rate: 2.5000e-05\n",
            "Epoch 129/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7381 - loss: 0.7587 - val_accuracy: 0.7568 - val_loss: 0.7225 - learning_rate: 2.5000e-05\n",
            "Epoch 130/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7320 - loss: 0.7919 - val_accuracy: 0.7549 - val_loss: 0.7270 - learning_rate: 2.5000e-05\n",
            "Epoch 131/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.7794 - val_accuracy: 0.7530 - val_loss: 0.7376 - learning_rate: 2.5000e-05\n",
            "Epoch 132/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7402 - loss: 0.7562 - val_accuracy: 0.7606 - val_loss: 0.7216 - learning_rate: 2.5000e-05\n",
            "Epoch 133/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.7577 - val_accuracy: 0.7573 - val_loss: 0.7258 - learning_rate: 2.5000e-05\n",
            "Epoch 134/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.7500 - val_accuracy: 0.7506 - val_loss: 0.7464 - learning_rate: 2.5000e-05\n",
            "Epoch 135/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.7830 - val_accuracy: 0.7544 - val_loss: 0.7320 - learning_rate: 2.5000e-05\n",
            "Epoch 136/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7328 - loss: 0.7747 - val_accuracy: 0.7601 - val_loss: 0.7274 - learning_rate: 2.5000e-05\n",
            "Epoch 137/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7453 - loss: 0.7677 - val_accuracy: 0.7587 - val_loss: 0.7198 - learning_rate: 2.5000e-05\n",
            "Epoch 138/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7401 - loss: 0.7582 - val_accuracy: 0.7558 - val_loss: 0.7237 - learning_rate: 2.5000e-05\n",
            "Epoch 139/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7485 - loss: 0.7608 - val_accuracy: 0.7587 - val_loss: 0.7320 - learning_rate: 2.5000e-05\n",
            "Epoch 140/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7522 - loss: 0.7508 - val_accuracy: 0.7577 - val_loss: 0.7341 - learning_rate: 2.5000e-05\n",
            "Epoch 141/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.7694 - val_accuracy: 0.7606 - val_loss: 0.7184 - learning_rate: 2.5000e-05\n",
            "Epoch 142/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7448 - loss: 0.7450 - val_accuracy: 0.7616 - val_loss: 0.7160 - learning_rate: 2.5000e-05\n",
            "Epoch 143/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7322 - loss: 0.7623 - val_accuracy: 0.7597 - val_loss: 0.7164 - learning_rate: 2.5000e-05\n",
            "Epoch 144/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7464 - loss: 0.7473 - val_accuracy: 0.7582 - val_loss: 0.7169 - learning_rate: 2.5000e-05\n",
            "Epoch 145/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7412 - loss: 0.7757 - val_accuracy: 0.7620 - val_loss: 0.7180 - learning_rate: 2.5000e-05\n",
            "Epoch 146/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.7588 - val_accuracy: 0.7601 - val_loss: 0.7123 - learning_rate: 2.5000e-05\n",
            "Epoch 147/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7396 - loss: 0.7645 - val_accuracy: 0.7654 - val_loss: 0.7115 - learning_rate: 2.5000e-05\n",
            "Epoch 148/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7414 - loss: 0.7638 - val_accuracy: 0.7611 - val_loss: 0.7102 - learning_rate: 2.5000e-05\n",
            "Epoch 149/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7282 - loss: 0.7776 - val_accuracy: 0.7587 - val_loss: 0.7155 - learning_rate: 2.5000e-05\n",
            "Epoch 150/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7408 - loss: 0.7525 - val_accuracy: 0.7630 - val_loss: 0.7141 - learning_rate: 2.5000e-05\n",
            "Epoch 151/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.7734 - val_accuracy: 0.7654 - val_loss: 0.7093 - learning_rate: 2.5000e-05\n",
            "Epoch 152/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7337 - loss: 0.7632 - val_accuracy: 0.7597 - val_loss: 0.7138 - learning_rate: 2.5000e-05\n",
            "Epoch 153/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7420 - loss: 0.7684 - val_accuracy: 0.7611 - val_loss: 0.7171 - learning_rate: 2.5000e-05\n",
            "Epoch 154/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7368 - loss: 0.7635 - val_accuracy: 0.7597 - val_loss: 0.7151 - learning_rate: 2.5000e-05\n",
            "Epoch 155/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7447 - loss: 0.7469 - val_accuracy: 0.7587 - val_loss: 0.7138 - learning_rate: 2.5000e-05\n",
            "Epoch 156/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.7605 - val_accuracy: 0.7620 - val_loss: 0.7059 - learning_rate: 2.5000e-05\n",
            "Epoch 157/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.7504 - val_accuracy: 0.7611 - val_loss: 0.7162 - learning_rate: 2.5000e-05\n",
            "Epoch 158/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.7455 - val_accuracy: 0.7659 - val_loss: 0.6997 - learning_rate: 2.5000e-05\n",
            "Epoch 159/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7367 - loss: 0.7770 - val_accuracy: 0.7601 - val_loss: 0.7125 - learning_rate: 2.5000e-05\n",
            "Epoch 160/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.7671 - val_accuracy: 0.7620 - val_loss: 0.7106 - learning_rate: 2.5000e-05\n",
            "Epoch 161/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7514 - loss: 0.7323 - val_accuracy: 0.7630 - val_loss: 0.7097 - learning_rate: 2.5000e-05\n",
            "Epoch 162/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7494 - loss: 0.7452 - val_accuracy: 0.7654 - val_loss: 0.7057 - learning_rate: 2.5000e-05\n",
            "Epoch 163/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7459 - loss: 0.7410 - val_accuracy: 0.7663 - val_loss: 0.7061 - learning_rate: 2.5000e-05\n",
            "Epoch 164/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7257 - loss: 0.7717 - val_accuracy: 0.7611 - val_loss: 0.7093 - learning_rate: 2.5000e-05\n",
            "Epoch 165/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7509 - loss: 0.7273 - val_accuracy: 0.7630 - val_loss: 0.7096 - learning_rate: 2.5000e-05\n",
            "Epoch 166/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.7675 - val_accuracy: 0.7592 - val_loss: 0.7138 - learning_rate: 2.5000e-05\n",
            "Epoch 167/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7468 - loss: 0.7563 - val_accuracy: 0.7625 - val_loss: 0.7066 - learning_rate: 2.5000e-05\n",
            "Epoch 168/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7476 - loss: 0.7351 - val_accuracy: 0.7644 - val_loss: 0.7063 - learning_rate: 2.5000e-05\n",
            "Epoch 169/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.7352 - val_accuracy: 0.7687 - val_loss: 0.6923 - learning_rate: 1.2500e-05\n",
            "Epoch 170/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7332 - loss: 0.7724 - val_accuracy: 0.7673 - val_loss: 0.6990 - learning_rate: 1.2500e-05\n",
            "Epoch 171/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7427 - loss: 0.7450 - val_accuracy: 0.7635 - val_loss: 0.7095 - learning_rate: 1.2500e-05\n",
            "Epoch 172/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 0.7358 - val_accuracy: 0.7682 - val_loss: 0.6977 - learning_rate: 1.2500e-05\n",
            "Epoch 173/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7538 - loss: 0.7399 - val_accuracy: 0.7659 - val_loss: 0.6969 - learning_rate: 1.2500e-05\n",
            "Epoch 174/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7464 - loss: 0.7443 - val_accuracy: 0.7654 - val_loss: 0.6995 - learning_rate: 1.2500e-05\n",
            "Epoch 175/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7407 - loss: 0.7492 - val_accuracy: 0.7659 - val_loss: 0.6998 - learning_rate: 1.2500e-05\n",
            "Epoch 176/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7473 - loss: 0.7395 - val_accuracy: 0.7663 - val_loss: 0.7028 - learning_rate: 1.2500e-05\n",
            "Epoch 177/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.7657 - val_accuracy: 0.7678 - val_loss: 0.6971 - learning_rate: 1.2500e-05\n",
            "Epoch 178/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7611 - loss: 0.7238 - val_accuracy: 0.7639 - val_loss: 0.7010 - learning_rate: 1.2500e-05\n",
            "Epoch 179/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7545 - loss: 0.7355 - val_accuracy: 0.7668 - val_loss: 0.6966 - learning_rate: 1.2500e-05\n",
            "Epoch 180/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7470 - loss: 0.7400 - val_accuracy: 0.7668 - val_loss: 0.7002 - learning_rate: 6.2500e-06\n",
            "Epoch 181/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7540 - loss: 0.7466 - val_accuracy: 0.7630 - val_loss: 0.7022 - learning_rate: 6.2500e-06\n",
            "Epoch 182/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7515 - loss: 0.7287 - val_accuracy: 0.7663 - val_loss: 0.6964 - learning_rate: 6.2500e-06\n",
            "Epoch 183/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7581 - loss: 0.7277 - val_accuracy: 0.7668 - val_loss: 0.6956 - learning_rate: 6.2500e-06\n",
            "Epoch 184/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7556 - loss: 0.7380 - val_accuracy: 0.7654 - val_loss: 0.6989 - learning_rate: 6.2500e-06\n",
            "Epoch 185/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7361 - loss: 0.7471 - val_accuracy: 0.7639 - val_loss: 0.6980 - learning_rate: 6.2500e-06\n",
            "Epoch 186/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7484 - loss: 0.7466 - val_accuracy: 0.7668 - val_loss: 0.7000 - learning_rate: 6.2500e-06\n",
            "Epoch 187/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7562 - loss: 0.7318 - val_accuracy: 0.7663 - val_loss: 0.6974 - learning_rate: 6.2500e-06\n",
            "Epoch 188/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7518 - loss: 0.7396 - val_accuracy: 0.7649 - val_loss: 0.6951 - learning_rate: 6.2500e-06\n",
            "Epoch 189/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7440 - loss: 0.7384 - val_accuracy: 0.7654 - val_loss: 0.6953 - learning_rate: 6.2500e-06\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7485 - loss: 0.6905\n",
            "Test Accuracy: 0.7553\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/sample_data/fcnn_splice_songs_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lAwurBUatqD",
        "outputId": "70755deb-8747-40c6-a1b2-d98c82707b57"
      },
      "id": "5lAwurBUatqD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FCNN with data augmentation"
      ],
      "metadata": {
        "id": "ZFF4evN9api8"
      },
      "id": "ZFF4evN9api8"
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import json\n",
        "\n",
        "# Enable mixed precision\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Parameters\n",
        "sample_rate = 22050\n",
        "n_mels = 130\n",
        "hop_length = 512\n",
        "segment_length = 3  # 3-second clips\n",
        "n_frames = int((segment_length * sample_rate / hop_length) + 1)  # ~129\n",
        "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "batch_size = 32  # Increased for GPU\n",
        "data_path = '/content/sample_data/data.json'  # Update with your GTZAN dataset path\n",
        "\n",
        "# Audio augmentations\n",
        "def augment_audio(audio, sr):\n",
        "    # Time-reversal (50% chance)\n",
        "    if np.random.rand() < 0.5:\n",
        "        audio = audio[::-1]\n",
        "    # Pitch shift (±2 semitones, 50% chance)\n",
        "    if np.random.rand() < 0.5:\n",
        "        n_steps = np.random.uniform(-2, 2)\n",
        "        audio = librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "    # Time stretch (0.8–1.2 rate, 50% chance)\n",
        "    if np.random.rand() < 0.5:\n",
        "        rate = np.random.uniform(0.8, 1.2)\n",
        "        audio = librosa.effects.time_stretch(audio, rate=rate)\n",
        "    return audio\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading and preprocessing data...\")\n",
        "\n",
        "with open(data_path, \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "# Define X nd y\n",
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"genre_num\"])\n",
        "\n",
        "# Train-validation-test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
        "X_val = X_val[..., np.newaxis]      # Add channel dimension\n",
        "X_test = X_test[..., np.newaxis]    # Add channel dimension\n",
        "\n",
        "# Create tf.data datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build FCNN\n",
        "def build_fcnn(input_shape=(n_mels, n_frames, 1), num_classes=10):\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax', dtype='float32')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Build and compile model\n",
        "model = build_fcnn()\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),  # Default Adam LR\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train with early stopping\n",
        "# Step 6: Train model on T4 GPU\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
        "# Train\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "print(\"Training model...\")\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=250,\n",
        "    callbacks=[early_stopping,lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Plot results\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "22STUyjhbek0",
        "outputId": "ffcd216d-27a2-4952-ea6c-70c01486f9a6"
      },
      "id": "22STUyjhbek0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,394\u001b[0m (95.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,394</span> (95.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,170\u001b[0m (94.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,170</span> (94.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Epoch 1/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - accuracy: 0.1735 - loss: 2.2694 - val_accuracy: 0.2656 - val_loss: 2.0975 - learning_rate: 1.0000e-04\n",
            "Epoch 2/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3529 - loss: 1.8371 - val_accuracy: 0.3338 - val_loss: 1.8692 - learning_rate: 1.0000e-04\n",
            "Epoch 3/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3985 - loss: 1.6930 - val_accuracy: 0.3815 - val_loss: 1.7301 - learning_rate: 1.0000e-04\n",
            "Epoch 4/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4328 - loss: 1.5730 - val_accuracy: 0.4235 - val_loss: 1.5929 - learning_rate: 1.0000e-04\n",
            "Epoch 5/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4769 - loss: 1.4810 - val_accuracy: 0.4669 - val_loss: 1.4873 - learning_rate: 1.0000e-04\n",
            "Epoch 6/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4879 - loss: 1.4347 - val_accuracy: 0.4964 - val_loss: 1.4274 - learning_rate: 1.0000e-04\n",
            "Epoch 7/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5142 - loss: 1.3817 - val_accuracy: 0.4902 - val_loss: 1.4188 - learning_rate: 1.0000e-04\n",
            "Epoch 8/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5162 - loss: 1.3563 - val_accuracy: 0.5155 - val_loss: 1.3628 - learning_rate: 1.0000e-04\n",
            "Epoch 9/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5239 - loss: 1.3352 - val_accuracy: 0.5136 - val_loss: 1.3566 - learning_rate: 1.0000e-04\n",
            "Epoch 10/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5404 - loss: 1.2990 - val_accuracy: 0.5203 - val_loss: 1.3402 - learning_rate: 1.0000e-04\n",
            "Epoch 11/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5504 - loss: 1.2689 - val_accuracy: 0.5341 - val_loss: 1.3124 - learning_rate: 1.0000e-04\n",
            "Epoch 12/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5561 - loss: 1.2646 - val_accuracy: 0.5513 - val_loss: 1.2829 - learning_rate: 1.0000e-04\n",
            "Epoch 13/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5524 - loss: 1.2453 - val_accuracy: 0.5393 - val_loss: 1.2856 - learning_rate: 1.0000e-04\n",
            "Epoch 14/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5798 - loss: 1.2005 - val_accuracy: 0.5551 - val_loss: 1.2689 - learning_rate: 1.0000e-04\n",
            "Epoch 15/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5744 - loss: 1.1995 - val_accuracy: 0.5498 - val_loss: 1.2684 - learning_rate: 1.0000e-04\n",
            "Epoch 16/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5817 - loss: 1.2053 - val_accuracy: 0.5579 - val_loss: 1.2622 - learning_rate: 1.0000e-04\n",
            "Epoch 17/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5853 - loss: 1.2031 - val_accuracy: 0.5756 - val_loss: 1.2207 - learning_rate: 1.0000e-04\n",
            "Epoch 18/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5849 - loss: 1.1701 - val_accuracy: 0.5694 - val_loss: 1.2249 - learning_rate: 1.0000e-04\n",
            "Epoch 19/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6079 - loss: 1.1454 - val_accuracy: 0.5794 - val_loss: 1.2039 - learning_rate: 1.0000e-04\n",
            "Epoch 20/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 1.1572 - val_accuracy: 0.5837 - val_loss: 1.2007 - learning_rate: 1.0000e-04\n",
            "Epoch 21/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6130 - loss: 1.1285 - val_accuracy: 0.5918 - val_loss: 1.1833 - learning_rate: 1.0000e-04\n",
            "Epoch 22/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5996 - loss: 1.1341 - val_accuracy: 0.6009 - val_loss: 1.1739 - learning_rate: 1.0000e-04\n",
            "Epoch 23/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6135 - loss: 1.1191 - val_accuracy: 0.6028 - val_loss: 1.1562 - learning_rate: 1.0000e-04\n",
            "Epoch 24/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6156 - loss: 1.0938 - val_accuracy: 0.6032 - val_loss: 1.1481 - learning_rate: 1.0000e-04\n",
            "Epoch 25/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6206 - loss: 1.1081 - val_accuracy: 0.6028 - val_loss: 1.1452 - learning_rate: 1.0000e-04\n",
            "Epoch 26/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6264 - loss: 1.0903 - val_accuracy: 0.6142 - val_loss: 1.1244 - learning_rate: 1.0000e-04\n",
            "Epoch 27/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6298 - loss: 1.0676 - val_accuracy: 0.6075 - val_loss: 1.1320 - learning_rate: 1.0000e-04\n",
            "Epoch 28/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6415 - loss: 1.0344 - val_accuracy: 0.6185 - val_loss: 1.1141 - learning_rate: 1.0000e-04\n",
            "Epoch 29/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6233 - loss: 1.0705 - val_accuracy: 0.6266 - val_loss: 1.0955 - learning_rate: 1.0000e-04\n",
            "Epoch 30/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6300 - loss: 1.0577 - val_accuracy: 0.6366 - val_loss: 1.0823 - learning_rate: 1.0000e-04\n",
            "Epoch 31/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6352 - loss: 1.0480 - val_accuracy: 0.6266 - val_loss: 1.0825 - learning_rate: 1.0000e-04\n",
            "Epoch 32/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6372 - loss: 1.0431 - val_accuracy: 0.6352 - val_loss: 1.0779 - learning_rate: 1.0000e-04\n",
            "Epoch 33/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6460 - loss: 1.0245 - val_accuracy: 0.6342 - val_loss: 1.0725 - learning_rate: 1.0000e-04\n",
            "Epoch 34/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6398 - loss: 1.0177 - val_accuracy: 0.6357 - val_loss: 1.0642 - learning_rate: 1.0000e-04\n",
            "Epoch 35/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6381 - loss: 1.0479 - val_accuracy: 0.6490 - val_loss: 1.0383 - learning_rate: 1.0000e-04\n",
            "Epoch 36/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6519 - loss: 1.0129 - val_accuracy: 0.6481 - val_loss: 1.0465 - learning_rate: 1.0000e-04\n",
            "Epoch 37/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6437 - loss: 1.0198 - val_accuracy: 0.6500 - val_loss: 1.0364 - learning_rate: 1.0000e-04\n",
            "Epoch 38/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6543 - loss: 0.9940 - val_accuracy: 0.6495 - val_loss: 1.0463 - learning_rate: 1.0000e-04\n",
            "Epoch 39/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6709 - loss: 0.9772 - val_accuracy: 0.6485 - val_loss: 1.0286 - learning_rate: 1.0000e-04\n",
            "Epoch 40/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6613 - loss: 0.9699 - val_accuracy: 0.6605 - val_loss: 1.0109 - learning_rate: 1.0000e-04\n",
            "Epoch 41/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6632 - loss: 0.9855 - val_accuracy: 0.6581 - val_loss: 1.0091 - learning_rate: 1.0000e-04\n",
            "Epoch 42/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6632 - loss: 0.9749 - val_accuracy: 0.6638 - val_loss: 0.9998 - learning_rate: 1.0000e-04\n",
            "Epoch 43/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6711 - loss: 0.9588 - val_accuracy: 0.6710 - val_loss: 0.9727 - learning_rate: 1.0000e-04\n",
            "Epoch 44/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6560 - loss: 0.9977 - val_accuracy: 0.6710 - val_loss: 0.9808 - learning_rate: 1.0000e-04\n",
            "Epoch 45/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6623 - loss: 0.9851 - val_accuracy: 0.6762 - val_loss: 0.9739 - learning_rate: 1.0000e-04\n",
            "Epoch 46/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6755 - loss: 0.9479 - val_accuracy: 0.6776 - val_loss: 0.9606 - learning_rate: 1.0000e-04\n",
            "Epoch 47/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6822 - loss: 0.9432 - val_accuracy: 0.6705 - val_loss: 0.9861 - learning_rate: 1.0000e-04\n",
            "Epoch 48/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6903 - loss: 0.9391 - val_accuracy: 0.6695 - val_loss: 0.9759 - learning_rate: 1.0000e-04\n",
            "Epoch 49/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6843 - loss: 0.9404 - val_accuracy: 0.6748 - val_loss: 0.9559 - learning_rate: 1.0000e-04\n",
            "Epoch 50/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6834 - loss: 0.9193 - val_accuracy: 0.6805 - val_loss: 0.9543 - learning_rate: 1.0000e-04\n",
            "Epoch 51/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6872 - loss: 0.9378 - val_accuracy: 0.6886 - val_loss: 0.9403 - learning_rate: 1.0000e-04\n",
            "Epoch 52/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6958 - loss: 0.8927 - val_accuracy: 0.6772 - val_loss: 0.9792 - learning_rate: 1.0000e-04\n",
            "Epoch 53/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6841 - loss: 0.9137 - val_accuracy: 0.6843 - val_loss: 0.9462 - learning_rate: 1.0000e-04\n",
            "Epoch 54/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6905 - loss: 0.8979 - val_accuracy: 0.6896 - val_loss: 0.9488 - learning_rate: 1.0000e-04\n",
            "Epoch 55/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6808 - loss: 0.9202 - val_accuracy: 0.6938 - val_loss: 0.9256 - learning_rate: 1.0000e-04\n",
            "Epoch 56/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6817 - loss: 0.9287 - val_accuracy: 0.6905 - val_loss: 0.9221 - learning_rate: 1.0000e-04\n",
            "Epoch 57/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6840 - loss: 0.9085 - val_accuracy: 0.6934 - val_loss: 0.9377 - learning_rate: 1.0000e-04\n",
            "Epoch 58/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.8920 - val_accuracy: 0.6896 - val_loss: 0.9267 - learning_rate: 1.0000e-04\n",
            "Epoch 59/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6936 - loss: 0.8867 - val_accuracy: 0.6924 - val_loss: 0.9138 - learning_rate: 1.0000e-04\n",
            "Epoch 60/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6807 - loss: 0.9117 - val_accuracy: 0.6919 - val_loss: 0.9305 - learning_rate: 1.0000e-04\n",
            "Epoch 61/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6990 - loss: 0.8899 - val_accuracy: 0.6948 - val_loss: 0.9241 - learning_rate: 1.0000e-04\n",
            "Epoch 62/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7009 - loss: 0.8732 - val_accuracy: 0.6896 - val_loss: 0.9233 - learning_rate: 1.0000e-04\n",
            "Epoch 63/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6960 - loss: 0.8885 - val_accuracy: 0.6919 - val_loss: 0.9149 - learning_rate: 1.0000e-04\n",
            "Epoch 64/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6888 - loss: 0.8765 - val_accuracy: 0.6929 - val_loss: 0.9047 - learning_rate: 1.0000e-04\n",
            "Epoch 65/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7038 - loss: 0.8570 - val_accuracy: 0.7020 - val_loss: 0.9031 - learning_rate: 1.0000e-04\n",
            "Epoch 66/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7109 - loss: 0.8429 - val_accuracy: 0.6924 - val_loss: 0.9215 - learning_rate: 1.0000e-04\n",
            "Epoch 67/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7040 - loss: 0.8700 - val_accuracy: 0.7000 - val_loss: 0.9017 - learning_rate: 1.0000e-04\n",
            "Epoch 68/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7075 - loss: 0.8609 - val_accuracy: 0.6986 - val_loss: 0.9059 - learning_rate: 1.0000e-04\n",
            "Epoch 69/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7038 - loss: 0.8603 - val_accuracy: 0.7110 - val_loss: 0.8692 - learning_rate: 1.0000e-04\n",
            "Epoch 70/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6897 - loss: 0.8691 - val_accuracy: 0.7096 - val_loss: 0.8714 - learning_rate: 1.0000e-04\n",
            "Epoch 71/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7058 - loss: 0.8589 - val_accuracy: 0.7105 - val_loss: 0.8625 - learning_rate: 1.0000e-04\n",
            "Epoch 72/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7110 - loss: 0.8387 - val_accuracy: 0.7010 - val_loss: 0.8832 - learning_rate: 1.0000e-04\n",
            "Epoch 73/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6998 - loss: 0.8463 - val_accuracy: 0.7053 - val_loss: 0.8841 - learning_rate: 1.0000e-04\n",
            "Epoch 74/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7107 - loss: 0.8500 - val_accuracy: 0.7048 - val_loss: 0.8873 - learning_rate: 1.0000e-04\n",
            "Epoch 75/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7171 - loss: 0.8276 - val_accuracy: 0.6996 - val_loss: 0.9060 - learning_rate: 1.0000e-04\n",
            "Epoch 76/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.8390 - val_accuracy: 0.7072 - val_loss: 0.8811 - learning_rate: 1.0000e-04\n",
            "Epoch 77/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7080 - loss: 0.8500 - val_accuracy: 0.7082 - val_loss: 0.8698 - learning_rate: 1.0000e-04\n",
            "Epoch 78/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7085 - loss: 0.8446 - val_accuracy: 0.7105 - val_loss: 0.8672 - learning_rate: 1.0000e-04\n",
            "Epoch 79/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7110 - loss: 0.8246 - val_accuracy: 0.7015 - val_loss: 0.8686 - learning_rate: 1.0000e-04\n",
            "Epoch 80/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6941 - loss: 0.8440 - val_accuracy: 0.7072 - val_loss: 0.8638 - learning_rate: 1.0000e-04\n",
            "Epoch 81/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7295 - loss: 0.7995 - val_accuracy: 0.7167 - val_loss: 0.8483 - learning_rate: 1.0000e-04\n",
            "Epoch 82/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6991 - loss: 0.8506 - val_accuracy: 0.7053 - val_loss: 0.8716 - learning_rate: 1.0000e-04\n",
            "Epoch 83/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7170 - loss: 0.8266 - val_accuracy: 0.7158 - val_loss: 0.8578 - learning_rate: 1.0000e-04\n",
            "Epoch 84/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7307 - loss: 0.7990 - val_accuracy: 0.7096 - val_loss: 0.8688 - learning_rate: 1.0000e-04\n",
            "Epoch 85/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.8026 - val_accuracy: 0.7148 - val_loss: 0.8445 - learning_rate: 1.0000e-04\n",
            "Epoch 86/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7242 - loss: 0.7805 - val_accuracy: 0.7148 - val_loss: 0.8478 - learning_rate: 1.0000e-04\n",
            "Epoch 87/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7328 - loss: 0.7896 - val_accuracy: 0.7201 - val_loss: 0.8314 - learning_rate: 1.0000e-04\n",
            "Epoch 88/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7318 - loss: 0.7901 - val_accuracy: 0.7229 - val_loss: 0.8306 - learning_rate: 1.0000e-04\n",
            "Epoch 89/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7183 - loss: 0.8080 - val_accuracy: 0.7124 - val_loss: 0.8390 - learning_rate: 1.0000e-04\n",
            "Epoch 90/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7263 - loss: 0.8007 - val_accuracy: 0.7244 - val_loss: 0.8246 - learning_rate: 1.0000e-04\n",
            "Epoch 91/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7226 - loss: 0.7917 - val_accuracy: 0.7153 - val_loss: 0.8366 - learning_rate: 1.0000e-04\n",
            "Epoch 92/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7279 - loss: 0.7881 - val_accuracy: 0.7239 - val_loss: 0.8212 - learning_rate: 1.0000e-04\n",
            "Epoch 93/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.7823 - val_accuracy: 0.7291 - val_loss: 0.8204 - learning_rate: 1.0000e-04\n",
            "Epoch 94/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7187 - loss: 0.8146 - val_accuracy: 0.7330 - val_loss: 0.8146 - learning_rate: 1.0000e-04\n",
            "Epoch 95/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7341 - loss: 0.7842 - val_accuracy: 0.7248 - val_loss: 0.8352 - learning_rate: 1.0000e-04\n",
            "Epoch 96/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.8020 - val_accuracy: 0.7220 - val_loss: 0.8222 - learning_rate: 1.0000e-04\n",
            "Epoch 97/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.7879 - val_accuracy: 0.7186 - val_loss: 0.8292 - learning_rate: 1.0000e-04\n",
            "Epoch 98/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7403 - loss: 0.7768 - val_accuracy: 0.7182 - val_loss: 0.8094 - learning_rate: 1.0000e-04\n",
            "Epoch 99/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7412 - loss: 0.7676 - val_accuracy: 0.7244 - val_loss: 0.8124 - learning_rate: 1.0000e-04\n",
            "Epoch 100/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7398 - loss: 0.7606 - val_accuracy: 0.7191 - val_loss: 0.8126 - learning_rate: 1.0000e-04\n",
            "Epoch 101/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7399 - loss: 0.7610 - val_accuracy: 0.7210 - val_loss: 0.8143 - learning_rate: 1.0000e-04\n",
            "Epoch 102/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7417 - loss: 0.7589 - val_accuracy: 0.7301 - val_loss: 0.8173 - learning_rate: 1.0000e-04\n",
            "Epoch 103/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7415 - loss: 0.7603 - val_accuracy: 0.7253 - val_loss: 0.8065 - learning_rate: 1.0000e-04\n",
            "Epoch 104/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7298 - loss: 0.7821 - val_accuracy: 0.7244 - val_loss: 0.7957 - learning_rate: 1.0000e-04\n",
            "Epoch 105/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7348 - loss: 0.7673 - val_accuracy: 0.7315 - val_loss: 0.7933 - learning_rate: 1.0000e-04\n",
            "Epoch 106/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7324 - loss: 0.7713 - val_accuracy: 0.7248 - val_loss: 0.7898 - learning_rate: 1.0000e-04\n",
            "Epoch 107/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.7750 - val_accuracy: 0.7277 - val_loss: 0.7991 - learning_rate: 1.0000e-04\n",
            "Epoch 108/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7389 - loss: 0.7517 - val_accuracy: 0.7377 - val_loss: 0.7731 - learning_rate: 1.0000e-04\n",
            "Epoch 109/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7407 - loss: 0.7616 - val_accuracy: 0.7291 - val_loss: 0.7838 - learning_rate: 1.0000e-04\n",
            "Epoch 110/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.7621 - val_accuracy: 0.7277 - val_loss: 0.7893 - learning_rate: 1.0000e-04\n",
            "Epoch 111/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7406 - loss: 0.7435 - val_accuracy: 0.7382 - val_loss: 0.7768 - learning_rate: 1.0000e-04\n",
            "Epoch 112/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7304 - loss: 0.7800 - val_accuracy: 0.7377 - val_loss: 0.7788 - learning_rate: 1.0000e-04\n",
            "Epoch 113/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7400 - loss: 0.7570 - val_accuracy: 0.7310 - val_loss: 0.7930 - learning_rate: 1.0000e-04\n",
            "Epoch 114/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7474 - loss: 0.7495 - val_accuracy: 0.7320 - val_loss: 0.7925 - learning_rate: 1.0000e-04\n",
            "Epoch 115/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7513 - loss: 0.7361 - val_accuracy: 0.7477 - val_loss: 0.7443 - learning_rate: 1.0000e-04\n",
            "Epoch 116/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7412 - loss: 0.7448 - val_accuracy: 0.7387 - val_loss: 0.7727 - learning_rate: 1.0000e-04\n",
            "Epoch 117/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7322 - loss: 0.7656 - val_accuracy: 0.7258 - val_loss: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 118/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.7378 - val_accuracy: 0.7463 - val_loss: 0.7492 - learning_rate: 1.0000e-04\n",
            "Epoch 119/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7450 - loss: 0.7348 - val_accuracy: 0.7406 - val_loss: 0.7633 - learning_rate: 1.0000e-04\n",
            "Epoch 120/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7568 - loss: 0.7120 - val_accuracy: 0.7434 - val_loss: 0.7632 - learning_rate: 1.0000e-04\n",
            "Epoch 121/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7523 - loss: 0.7239 - val_accuracy: 0.7306 - val_loss: 0.7811 - learning_rate: 1.0000e-04\n",
            "Epoch 122/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7567 - loss: 0.7152 - val_accuracy: 0.7439 - val_loss: 0.7601 - learning_rate: 1.0000e-04\n",
            "Epoch 123/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7572 - loss: 0.7099 - val_accuracy: 0.7434 - val_loss: 0.7449 - learning_rate: 1.0000e-04\n",
            "Epoch 124/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7591 - loss: 0.7142 - val_accuracy: 0.7487 - val_loss: 0.7530 - learning_rate: 1.0000e-04\n",
            "Epoch 125/250\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7478 - loss: 0.7131 - val_accuracy: 0.7301 - val_loss: 0.7937 - learning_rate: 1.0000e-04\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7461 - loss: 0.7122\n",
            "Test Loss: 0.7216\n",
            "Test Accuracy: 0.7480\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('fcnn_genre_classification_data_aug_model.h5')"
      ],
      "metadata": {
        "id": "MhN1MaY8Hvtb",
        "outputId": "d2c15538-2682-499c-b34e-b476c3916e83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MhN1MaY8Hvtb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}