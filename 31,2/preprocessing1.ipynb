{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "rl8Y8SZ8VQKW",
      "metadata": {
        "id": "rl8Y8SZ8VQKW"
      },
      "source": [
        "## FCNN without dataslicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a970506e",
      "metadata": {
        "id": "a970506e"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f670cfcf",
      "metadata": {
        "id": "f670cfcf"
      },
      "outputs": [],
      "source": [
        "sample_rate = 22050\n",
        "n_mels = 130\n",
        "hop_length = 512\n",
        "n_frames = 13\n",
        "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6aa3d9a0",
      "metadata": {
        "id": "6aa3d9a0"
      },
      "outputs": [],
      "source": [
        "def augment_audio(audio, sr):\n",
        "\n",
        "    audio_shifted = librosa.effects.pitch_shift(audio, n_steps=np.random.randint(-2, 2), sr=sr)\n",
        "    audio_stretched = librosa.effects.time_stretch(audio, rate=np.random.uniform(0.8, 1.2))\n",
        "    return audio_shifted, audio_stretched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "23af3f01",
      "metadata": {
        "id": "23af3f01"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/sample_data/data.json'\n",
        "\n",
        "with open(data_path, \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "# Define X nd y\n",
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"genre_num\"])\n",
        "# Train-validation-test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
        "X_val = X_val[..., np.newaxis]      # Add channel dimension\n",
        "X_test = X_test[..., np.newaxis]    # Add channel dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "773e4d26",
      "metadata": {
        "id": "773e4d26"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Dense\n",
        "\n",
        "def build_fcnn(input_shape=(n_mels, n_frames, 1),num_classes=10):\n",
        "    model = Sequential([\n",
        "        #layer 1\n",
        "        Conv2D(32, (3,3), activation='relu',padding='same',input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        #layer 2\n",
        "        Conv2D(64, (3,3), activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        #layer 3\n",
        "        Conv2D(128, (3,3), activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        #layer 4\n",
        "        Conv2D(128, (3,3), activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        GlobalAveragePooling2D(), #Replaces dense layers\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9j1gGbpuRVvu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j1gGbpuRVvu",
        "outputId": "ffe7181c-bc64-4199-9e75-b43b80a46c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b78465db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "b78465db",
        "outputId": "c7ffb024-b896-45ee-bfc6-f660739cb9fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249,920</span> (976.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m249,920\u001b[0m (976.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249,216</span> (973.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m249,216\u001b[0m (973.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 5: Build, compile, and summarize model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model = build_fcnn()\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),  # Default Adam LR\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9758ff3",
      "metadata": {
        "id": "e9758ff3"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ab1ff28f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab1ff28f",
        "outputId": "fb7e523e-18ef-4238-c9b3-cee0d6b869f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - accuracy: 0.2948 - loss: 3.0047 - val_accuracy: 0.2003 - val_loss: 4.5167 - learning_rate: 0.0010\n",
            "Epoch 2/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5747 - loss: 1.3837 - val_accuracy: 0.4764 - val_loss: 1.5750 - learning_rate: 0.0010\n",
            "Epoch 3/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6304 - loss: 1.1379 - val_accuracy: 0.5627 - val_loss: 1.2544 - learning_rate: 0.0010\n",
            "Epoch 4/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6795 - loss: 0.9955 - val_accuracy: 0.5784 - val_loss: 1.3065 - learning_rate: 0.0010\n",
            "Epoch 5/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7102 - loss: 0.8910 - val_accuracy: 0.6271 - val_loss: 1.1354 - learning_rate: 0.0010\n",
            "Epoch 6/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7175 - loss: 0.8308 - val_accuracy: 0.6237 - val_loss: 1.3123 - learning_rate: 0.0010\n",
            "Epoch 7/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7472 - loss: 0.7252 - val_accuracy: 0.6428 - val_loss: 1.1901 - learning_rate: 0.0010\n",
            "Epoch 8/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7674 - loss: 0.6753 - val_accuracy: 0.6609 - val_loss: 1.0791 - learning_rate: 0.0010\n",
            "Epoch 9/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7755 - loss: 0.6346 - val_accuracy: 0.7244 - val_loss: 0.9196 - learning_rate: 0.0010\n",
            "Epoch 10/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7919 - loss: 0.6197 - val_accuracy: 0.7682 - val_loss: 0.7226 - learning_rate: 0.0010\n",
            "Epoch 11/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7951 - loss: 0.6078 - val_accuracy: 0.8050 - val_loss: 0.6277 - learning_rate: 0.0010\n",
            "Epoch 12/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8137 - loss: 0.5566 - val_accuracy: 0.7935 - val_loss: 0.6332 - learning_rate: 0.0010\n",
            "Epoch 13/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8120 - loss: 0.5379 - val_accuracy: 0.8112 - val_loss: 0.5939 - learning_rate: 0.0010\n",
            "Epoch 14/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8327 - loss: 0.5136 - val_accuracy: 0.7554 - val_loss: 0.7585 - learning_rate: 0.0010\n",
            "Epoch 15/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8280 - loss: 0.4935 - val_accuracy: 0.7992 - val_loss: 0.6886 - learning_rate: 0.0010\n",
            "Epoch 16/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 0.4832 - val_accuracy: 0.7935 - val_loss: 0.6300 - learning_rate: 0.0010\n",
            "Epoch 17/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8414 - loss: 0.4474 - val_accuracy: 0.7916 - val_loss: 0.7002 - learning_rate: 0.0010\n",
            "Epoch 18/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.3817 - val_accuracy: 0.7997 - val_loss: 0.6247 - learning_rate: 0.0010\n",
            "Epoch 19/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8531 - loss: 0.3955 - val_accuracy: 0.8302 - val_loss: 0.5211 - learning_rate: 0.0010\n",
            "Epoch 20/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8630 - loss: 0.3800 - val_accuracy: 0.8426 - val_loss: 0.5143 - learning_rate: 0.0010\n",
            "Epoch 21/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.3720 - val_accuracy: 0.8417 - val_loss: 0.5385 - learning_rate: 0.0010\n",
            "Epoch 22/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8718 - loss: 0.3720 - val_accuracy: 0.8288 - val_loss: 0.5365 - learning_rate: 0.0010\n",
            "Epoch 23/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8647 - loss: 0.3899 - val_accuracy: 0.8355 - val_loss: 0.5114 - learning_rate: 0.0010\n",
            "Epoch 24/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8793 - loss: 0.3371 - val_accuracy: 0.8236 - val_loss: 0.5580 - learning_rate: 0.0010\n",
            "Epoch 25/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8809 - loss: 0.3344 - val_accuracy: 0.8398 - val_loss: 0.5027 - learning_rate: 0.0010\n",
            "Epoch 26/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8971 - loss: 0.2974 - val_accuracy: 0.8293 - val_loss: 0.5482 - learning_rate: 0.0010\n",
            "Epoch 27/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8823 - loss: 0.3253 - val_accuracy: 0.8412 - val_loss: 0.5317 - learning_rate: 0.0010\n",
            "Epoch 28/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8925 - loss: 0.3184 - val_accuracy: 0.8188 - val_loss: 0.6131 - learning_rate: 0.0010\n",
            "Epoch 29/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8842 - loss: 0.3136 - val_accuracy: 0.8464 - val_loss: 0.5099 - learning_rate: 0.0010\n",
            "Epoch 30/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8915 - loss: 0.3019 - val_accuracy: 0.8412 - val_loss: 0.5333 - learning_rate: 0.0010\n",
            "Epoch 31/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9084 - loss: 0.2747 - val_accuracy: 0.8584 - val_loss: 0.4945 - learning_rate: 0.0010\n",
            "Epoch 32/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2618 - val_accuracy: 0.8569 - val_loss: 0.4735 - learning_rate: 0.0010\n",
            "Epoch 33/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2331 - val_accuracy: 0.8312 - val_loss: 0.6009 - learning_rate: 0.0010\n",
            "Epoch 34/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9138 - loss: 0.2453 - val_accuracy: 0.8274 - val_loss: 0.5670 - learning_rate: 0.0010\n",
            "Epoch 35/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9042 - loss: 0.2715 - val_accuracy: 0.8503 - val_loss: 0.5144 - learning_rate: 0.0010\n",
            "Epoch 36/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9146 - loss: 0.2352 - val_accuracy: 0.8522 - val_loss: 0.5179 - learning_rate: 0.0010\n",
            "Epoch 37/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9258 - loss: 0.2212 - val_accuracy: 0.8798 - val_loss: 0.4254 - learning_rate: 0.0010\n",
            "Epoch 38/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9205 - loss: 0.2390 - val_accuracy: 0.8522 - val_loss: 0.5102 - learning_rate: 0.0010\n",
            "Epoch 39/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9209 - loss: 0.2365 - val_accuracy: 0.8670 - val_loss: 0.4571 - learning_rate: 0.0010\n",
            "Epoch 40/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.2197 - val_accuracy: 0.8650 - val_loss: 0.4831 - learning_rate: 0.0010\n",
            "Epoch 41/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9311 - loss: 0.2051 - val_accuracy: 0.8641 - val_loss: 0.4595 - learning_rate: 0.0010\n",
            "Epoch 42/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9341 - loss: 0.1905 - val_accuracy: 0.8693 - val_loss: 0.4645 - learning_rate: 0.0010\n",
            "Epoch 43/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9257 - loss: 0.2069 - val_accuracy: 0.8574 - val_loss: 0.4984 - learning_rate: 0.0010\n",
            "Epoch 44/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9234 - loss: 0.2188 - val_accuracy: 0.8636 - val_loss: 0.4728 - learning_rate: 0.0010\n",
            "Epoch 45/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.1904 - val_accuracy: 0.8832 - val_loss: 0.4161 - learning_rate: 0.0010\n",
            "Epoch 46/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9338 - loss: 0.2052 - val_accuracy: 0.8827 - val_loss: 0.4058 - learning_rate: 0.0010\n",
            "Epoch 47/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9380 - loss: 0.1837 - val_accuracy: 0.8808 - val_loss: 0.4246 - learning_rate: 0.0010\n",
            "Epoch 48/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9323 - loss: 0.1939 - val_accuracy: 0.8689 - val_loss: 0.4777 - learning_rate: 0.0010\n",
            "Epoch 49/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9356 - loss: 0.1806 - val_accuracy: 0.8898 - val_loss: 0.3650 - learning_rate: 0.0010\n",
            "Epoch 50/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9361 - loss: 0.1800 - val_accuracy: 0.8832 - val_loss: 0.3940 - learning_rate: 0.0010\n",
            "Epoch 51/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9260 - loss: 0.1948 - val_accuracy: 0.8932 - val_loss: 0.3758 - learning_rate: 0.0010\n",
            "Epoch 52/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9361 - loss: 0.1747 - val_accuracy: 0.8898 - val_loss: 0.4117 - learning_rate: 0.0010\n",
            "Epoch 53/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.1629 - val_accuracy: 0.8631 - val_loss: 0.4902 - learning_rate: 0.0010\n",
            "Epoch 54/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9325 - loss: 0.1875 - val_accuracy: 0.8884 - val_loss: 0.3947 - learning_rate: 0.0010\n",
            "Epoch 55/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.1562 - val_accuracy: 0.8846 - val_loss: 0.4440 - learning_rate: 0.0010\n",
            "Epoch 56/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.1542 - val_accuracy: 0.8817 - val_loss: 0.4534 - learning_rate: 0.0010\n",
            "Epoch 57/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9427 - loss: 0.1692 - val_accuracy: 0.8856 - val_loss: 0.3950 - learning_rate: 0.0010\n",
            "Epoch 58/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9368 - loss: 0.1680 - val_accuracy: 0.8903 - val_loss: 0.4128 - learning_rate: 0.0010\n",
            "Epoch 59/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.1489 - val_accuracy: 0.8703 - val_loss: 0.4701 - learning_rate: 0.0010\n",
            "Epoch 60/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9570 - loss: 0.1281 - val_accuracy: 0.8908 - val_loss: 0.3776 - learning_rate: 5.0000e-04\n",
            "Epoch 61/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9612 - loss: 0.1101 - val_accuracy: 0.9041 - val_loss: 0.3473 - learning_rate: 5.0000e-04\n",
            "Epoch 62/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9656 - loss: 0.1025 - val_accuracy: 0.9032 - val_loss: 0.3653 - learning_rate: 5.0000e-04\n",
            "Epoch 63/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.1185 - val_accuracy: 0.8984 - val_loss: 0.3776 - learning_rate: 5.0000e-04\n",
            "Epoch 64/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9587 - loss: 0.1129 - val_accuracy: 0.8989 - val_loss: 0.3928 - learning_rate: 5.0000e-04\n",
            "Epoch 65/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9587 - loss: 0.1171 - val_accuracy: 0.8970 - val_loss: 0.4014 - learning_rate: 5.0000e-04\n",
            "Epoch 66/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.0931 - val_accuracy: 0.8960 - val_loss: 0.3941 - learning_rate: 5.0000e-04\n",
            "Epoch 67/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9653 - loss: 0.1026 - val_accuracy: 0.8965 - val_loss: 0.3591 - learning_rate: 5.0000e-04\n",
            "Epoch 68/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0918 - val_accuracy: 0.8946 - val_loss: 0.3853 - learning_rate: 5.0000e-04\n",
            "Epoch 69/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9670 - loss: 0.0937 - val_accuracy: 0.9027 - val_loss: 0.3538 - learning_rate: 5.0000e-04\n",
            "Epoch 70/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9649 - loss: 0.0958 - val_accuracy: 0.8908 - val_loss: 0.3948 - learning_rate: 5.0000e-04\n",
            "Epoch 71/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9650 - loss: 0.1042 - val_accuracy: 0.8999 - val_loss: 0.3718 - learning_rate: 5.0000e-04\n",
            "Epoch 72/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9710 - loss: 0.0854 - val_accuracy: 0.9113 - val_loss: 0.3301 - learning_rate: 2.5000e-04\n",
            "Epoch 73/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9713 - loss: 0.0794 - val_accuracy: 0.9099 - val_loss: 0.3383 - learning_rate: 2.5000e-04\n",
            "Epoch 74/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9682 - loss: 0.0923 - val_accuracy: 0.9156 - val_loss: 0.3340 - learning_rate: 2.5000e-04\n",
            "Epoch 75/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9714 - loss: 0.0747 - val_accuracy: 0.8960 - val_loss: 0.3804 - learning_rate: 2.5000e-04\n",
            "Epoch 76/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0720 - val_accuracy: 0.9103 - val_loss: 0.3306 - learning_rate: 2.5000e-04\n",
            "Epoch 77/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.0997 - val_accuracy: 0.9094 - val_loss: 0.3526 - learning_rate: 2.5000e-04\n",
            "Epoch 78/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9751 - loss: 0.0783 - val_accuracy: 0.9156 - val_loss: 0.3341 - learning_rate: 2.5000e-04\n",
            "Epoch 79/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0726 - val_accuracy: 0.9094 - val_loss: 0.3459 - learning_rate: 2.5000e-04\n",
            "Epoch 80/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0696 - val_accuracy: 0.9089 - val_loss: 0.3611 - learning_rate: 2.5000e-04\n",
            "Epoch 81/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9717 - loss: 0.0809 - val_accuracy: 0.9118 - val_loss: 0.3530 - learning_rate: 2.5000e-04\n",
            "Epoch 82/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0785 - val_accuracy: 0.9080 - val_loss: 0.3710 - learning_rate: 2.5000e-04\n",
            "Epoch 83/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9656 - loss: 0.0865 - val_accuracy: 0.9137 - val_loss: 0.3397 - learning_rate: 1.2500e-04\n",
            "Epoch 84/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9774 - loss: 0.0714 - val_accuracy: 0.9142 - val_loss: 0.3407 - learning_rate: 1.2500e-04\n",
            "Epoch 85/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9753 - loss: 0.0756 - val_accuracy: 0.9113 - val_loss: 0.3593 - learning_rate: 1.2500e-04\n",
            "Epoch 86/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9812 - loss: 0.0614 - val_accuracy: 0.9123 - val_loss: 0.3492 - learning_rate: 1.2500e-04\n",
            "Epoch 87/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0632 - val_accuracy: 0.9123 - val_loss: 0.3490 - learning_rate: 1.2500e-04\n",
            "Epoch 88/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0618 - val_accuracy: 0.9175 - val_loss: 0.3207 - learning_rate: 1.2500e-04\n",
            "Epoch 89/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9816 - loss: 0.0579 - val_accuracy: 0.9151 - val_loss: 0.3414 - learning_rate: 1.2500e-04\n",
            "Epoch 90/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9766 - loss: 0.0602 - val_accuracy: 0.9170 - val_loss: 0.3274 - learning_rate: 1.2500e-04\n",
            "Epoch 91/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.0605 - val_accuracy: 0.9132 - val_loss: 0.3442 - learning_rate: 1.2500e-04\n",
            "Epoch 92/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.0562 - val_accuracy: 0.9213 - val_loss: 0.3123 - learning_rate: 1.2500e-04\n",
            "Epoch 93/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9805 - loss: 0.0556 - val_accuracy: 0.9161 - val_loss: 0.3210 - learning_rate: 1.2500e-04\n",
            "Epoch 94/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0575 - val_accuracy: 0.9165 - val_loss: 0.3224 - learning_rate: 1.2500e-04\n",
            "Epoch 95/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0664 - val_accuracy: 0.9175 - val_loss: 0.3281 - learning_rate: 1.2500e-04\n",
            "Epoch 96/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0583 - val_accuracy: 0.9151 - val_loss: 0.3364 - learning_rate: 1.2500e-04\n",
            "Epoch 97/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9784 - loss: 0.0638 - val_accuracy: 0.9185 - val_loss: 0.3441 - learning_rate: 1.2500e-04\n",
            "Epoch 98/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0669 - val_accuracy: 0.9123 - val_loss: 0.3536 - learning_rate: 1.2500e-04\n",
            "Epoch 99/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9816 - loss: 0.0559 - val_accuracy: 0.9151 - val_loss: 0.3463 - learning_rate: 1.2500e-04\n",
            "Epoch 100/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0731 - val_accuracy: 0.9127 - val_loss: 0.3368 - learning_rate: 1.2500e-04\n",
            "Epoch 101/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9788 - loss: 0.0633 - val_accuracy: 0.9123 - val_loss: 0.3432 - learning_rate: 1.2500e-04\n",
            "Epoch 102/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9697 - loss: 0.0736 - val_accuracy: 0.9142 - val_loss: 0.3389 - learning_rate: 1.2500e-04\n",
            "Epoch 103/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.0688 - val_accuracy: 0.9161 - val_loss: 0.3346 - learning_rate: 6.2500e-05\n",
            "Epoch 104/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9867 - loss: 0.0508 - val_accuracy: 0.9170 - val_loss: 0.3305 - learning_rate: 6.2500e-05\n",
            "Epoch 105/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0503 - val_accuracy: 0.9151 - val_loss: 0.3273 - learning_rate: 6.2500e-05\n",
            "Epoch 106/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9791 - loss: 0.0611 - val_accuracy: 0.9170 - val_loss: 0.3320 - learning_rate: 6.2500e-05\n",
            "Epoch 107/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.0627 - val_accuracy: 0.9123 - val_loss: 0.3329 - learning_rate: 6.2500e-05\n",
            "Epoch 108/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.0476 - val_accuracy: 0.9170 - val_loss: 0.3285 - learning_rate: 6.2500e-05\n",
            "Epoch 109/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0591 - val_accuracy: 0.9165 - val_loss: 0.3423 - learning_rate: 6.2500e-05\n",
            "Epoch 110/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9825 - loss: 0.0531 - val_accuracy: 0.9189 - val_loss: 0.3314 - learning_rate: 6.2500e-05\n",
            "Epoch 111/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9760 - loss: 0.0620 - val_accuracy: 0.9146 - val_loss: 0.3362 - learning_rate: 6.2500e-05\n",
            "Epoch 112/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.0487 - val_accuracy: 0.9199 - val_loss: 0.3244 - learning_rate: 6.2500e-05\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9220 - loss: 0.3034\n",
            "Test_accuracy : 0.9212\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "\n",
        "# Step 6: Train model on T4 GPU\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=250,\n",
        "                    batch_size=64,\n",
        "                    callbacks=[early_stopping,lr_scheduler])\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test_accuracy : {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ee5b07d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee5b07d3",
        "outputId": "f6e2db83-9758-46a2-8cc7-98aa0befaa00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('/content/sample_data/fcnn_melspec_gtzan.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rWocEPYyVgRN",
      "metadata": {
        "id": "rWocEPYyVgRN"
      },
      "source": [
        "## FCNN with data slicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H-InjY9VVf6V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H-InjY9VVf6V",
        "outputId": "0b0ac535-c8f4-4812-84fd-c56efb8366a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preprocessing data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,394</span> (95.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,394\u001b[0m (95.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,170</span> (94.41 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,170\u001b[0m (94.41 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "Epoch 1/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.3796 - loss: 1.7393 - val_accuracy: 0.5098 - val_loss: 1.3425 - learning_rate: 0.0010\n",
            "Epoch 2/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5611 - loss: 1.2835 - val_accuracy: 0.5832 - val_loss: 1.2021 - learning_rate: 0.0010\n",
            "Epoch 3/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5900 - loss: 1.1820 - val_accuracy: 0.6357 - val_loss: 1.0807 - learning_rate: 0.0010\n",
            "Epoch 4/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6148 - loss: 1.1112 - val_accuracy: 0.6500 - val_loss: 1.0102 - learning_rate: 0.0010\n",
            "Epoch 5/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6292 - loss: 1.0644 - val_accuracy: 0.5937 - val_loss: 1.1470 - learning_rate: 0.0010\n",
            "Epoch 6/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6381 - loss: 1.0511 - val_accuracy: 0.6452 - val_loss: 1.0348 - learning_rate: 0.0010\n",
            "Epoch 7/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.9743 - val_accuracy: 0.6490 - val_loss: 1.0860 - learning_rate: 0.0010\n",
            "Epoch 8/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6666 - loss: 0.9801 - val_accuracy: 0.7110 - val_loss: 0.8718 - learning_rate: 0.0010\n",
            "Epoch 9/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6671 - loss: 0.9554 - val_accuracy: 0.6662 - val_loss: 0.9752 - learning_rate: 0.0010\n",
            "Epoch 10/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6769 - loss: 0.9414 - val_accuracy: 0.6590 - val_loss: 1.0013 - learning_rate: 0.0010\n",
            "Epoch 11/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6762 - loss: 0.9229 - val_accuracy: 0.6996 - val_loss: 0.9002 - learning_rate: 0.0010\n",
            "Epoch 12/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6951 - loss: 0.8587 - val_accuracy: 0.6962 - val_loss: 0.9021 - learning_rate: 0.0010\n",
            "Epoch 13/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6998 - loss: 0.8755 - val_accuracy: 0.7444 - val_loss: 0.7823 - learning_rate: 0.0010\n",
            "Epoch 14/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 0.8552 - val_accuracy: 0.7110 - val_loss: 0.8657 - learning_rate: 0.0010\n",
            "Epoch 15/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7172 - loss: 0.8394 - val_accuracy: 0.7239 - val_loss: 0.8040 - learning_rate: 0.0010\n",
            "Epoch 16/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7170 - loss: 0.8234 - val_accuracy: 0.7029 - val_loss: 0.8790 - learning_rate: 0.0010\n",
            "Epoch 17/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7051 - loss: 0.8327 - val_accuracy: 0.7473 - val_loss: 0.7674 - learning_rate: 0.0010\n",
            "Epoch 18/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7038 - loss: 0.8520 - val_accuracy: 0.7515 - val_loss: 0.7690 - learning_rate: 0.0010\n",
            "Epoch 19/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7159 - loss: 0.8158 - val_accuracy: 0.7201 - val_loss: 0.8479 - learning_rate: 0.0010\n",
            "Epoch 20/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7286 - loss: 0.7822 - val_accuracy: 0.7287 - val_loss: 0.7983 - learning_rate: 0.0010\n",
            "Epoch 21/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7274 - loss: 0.7833 - val_accuracy: 0.7496 - val_loss: 0.7680 - learning_rate: 0.0010\n",
            "Epoch 22/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7275 - loss: 0.7763 - val_accuracy: 0.7716 - val_loss: 0.7208 - learning_rate: 0.0010\n",
            "Epoch 23/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7386 - loss: 0.7579 - val_accuracy: 0.7639 - val_loss: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 24/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.7409 - val_accuracy: 0.7897 - val_loss: 0.6738 - learning_rate: 0.0010\n",
            "Epoch 25/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7489 - loss: 0.7435 - val_accuracy: 0.7563 - val_loss: 0.7397 - learning_rate: 0.0010\n",
            "Epoch 26/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.7499 - val_accuracy: 0.7597 - val_loss: 0.7515 - learning_rate: 0.0010\n",
            "Epoch 27/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.7186 - val_accuracy: 0.7740 - val_loss: 0.7146 - learning_rate: 0.0010\n",
            "Epoch 28/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7457 - loss: 0.7320 - val_accuracy: 0.7792 - val_loss: 0.6712 - learning_rate: 0.0010\n",
            "Epoch 29/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7581 - loss: 0.7133 - val_accuracy: 0.7849 - val_loss: 0.6489 - learning_rate: 0.0010\n",
            "Epoch 30/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.6751 - val_accuracy: 0.7396 - val_loss: 0.7851 - learning_rate: 0.0010\n",
            "Epoch 31/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7503 - loss: 0.7185 - val_accuracy: 0.8035 - val_loss: 0.6458 - learning_rate: 0.0010\n",
            "Epoch 32/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7640 - loss: 0.6803 - val_accuracy: 0.7620 - val_loss: 0.7466 - learning_rate: 0.0010\n",
            "Epoch 33/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7676 - loss: 0.6759 - val_accuracy: 0.7787 - val_loss: 0.6812 - learning_rate: 0.0010\n",
            "Epoch 34/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7502 - loss: 0.7154 - val_accuracy: 0.7930 - val_loss: 0.6610 - learning_rate: 0.0010\n",
            "Epoch 35/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.6717 - val_accuracy: 0.7849 - val_loss: 0.6611 - learning_rate: 0.0010\n",
            "Epoch 36/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7663 - loss: 0.6796 - val_accuracy: 0.7830 - val_loss: 0.6602 - learning_rate: 0.0010\n",
            "Epoch 37/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7594 - loss: 0.6655 - val_accuracy: 0.8069 - val_loss: 0.6177 - learning_rate: 0.0010\n",
            "Epoch 38/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7663 - loss: 0.6697 - val_accuracy: 0.8255 - val_loss: 0.5606 - learning_rate: 0.0010\n",
            "Epoch 39/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7824 - loss: 0.6286 - val_accuracy: 0.8164 - val_loss: 0.5846 - learning_rate: 0.0010\n",
            "Epoch 40/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7743 - loss: 0.6393 - val_accuracy: 0.8107 - val_loss: 0.6120 - learning_rate: 0.0010\n",
            "Epoch 41/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7760 - loss: 0.6466 - val_accuracy: 0.7792 - val_loss: 0.6983 - learning_rate: 0.0010\n",
            "Epoch 42/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.6404 - val_accuracy: 0.8116 - val_loss: 0.5741 - learning_rate: 0.0010\n",
            "Epoch 43/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.6648 - val_accuracy: 0.8207 - val_loss: 0.5552 - learning_rate: 0.0010\n",
            "Epoch 44/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7632 - loss: 0.6663 - val_accuracy: 0.8207 - val_loss: 0.5668 - learning_rate: 0.0010\n",
            "Epoch 45/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7773 - loss: 0.6422 - val_accuracy: 0.8126 - val_loss: 0.5882 - learning_rate: 0.0010\n",
            "Epoch 46/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7817 - loss: 0.6228 - val_accuracy: 0.8169 - val_loss: 0.5960 - learning_rate: 0.0010\n",
            "Epoch 47/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.6142 - val_accuracy: 0.8159 - val_loss: 0.5990 - learning_rate: 0.0010\n",
            "Epoch 48/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7773 - loss: 0.6327 - val_accuracy: 0.8116 - val_loss: 0.5958 - learning_rate: 0.0010\n",
            "Epoch 49/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7874 - loss: 0.6185 - val_accuracy: 0.8207 - val_loss: 0.5585 - learning_rate: 0.0010\n",
            "Epoch 50/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.5936 - val_accuracy: 0.8073 - val_loss: 0.6251 - learning_rate: 0.0010\n",
            "Epoch 51/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 0.6138 - val_accuracy: 0.8240 - val_loss: 0.5653 - learning_rate: 0.0010\n",
            "Epoch 52/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.6055 - val_accuracy: 0.8093 - val_loss: 0.6142 - learning_rate: 0.0010\n",
            "Epoch 53/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7909 - loss: 0.6130 - val_accuracy: 0.8250 - val_loss: 0.5525 - learning_rate: 0.0010\n",
            "Epoch 54/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7936 - loss: 0.5936 - val_accuracy: 0.8293 - val_loss: 0.5551 - learning_rate: 0.0010\n",
            "Epoch 55/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7956 - loss: 0.5964 - val_accuracy: 0.8312 - val_loss: 0.5587 - learning_rate: 0.0010\n",
            "Epoch 56/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.6143 - val_accuracy: 0.8197 - val_loss: 0.5657 - learning_rate: 0.0010\n",
            "Epoch 57/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.5792 - val_accuracy: 0.8150 - val_loss: 0.5897 - learning_rate: 0.0010\n",
            "Epoch 58/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7867 - loss: 0.6101 - val_accuracy: 0.8274 - val_loss: 0.5303 - learning_rate: 0.0010\n",
            "Epoch 59/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.5760 - val_accuracy: 0.8302 - val_loss: 0.5415 - learning_rate: 0.0010\n",
            "Epoch 60/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.5984 - val_accuracy: 0.8259 - val_loss: 0.5476 - learning_rate: 0.0010\n",
            "Epoch 61/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7995 - loss: 0.5751 - val_accuracy: 0.8293 - val_loss: 0.5285 - learning_rate: 0.0010\n",
            "Epoch 62/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7982 - loss: 0.6047 - val_accuracy: 0.8364 - val_loss: 0.5227 - learning_rate: 0.0010\n",
            "Epoch 63/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.5818 - val_accuracy: 0.8298 - val_loss: 0.5562 - learning_rate: 0.0010\n",
            "Epoch 64/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7986 - loss: 0.5892 - val_accuracy: 0.8274 - val_loss: 0.5734 - learning_rate: 0.0010\n",
            "Epoch 65/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7991 - loss: 0.5813 - val_accuracy: 0.8188 - val_loss: 0.5601 - learning_rate: 0.0010\n",
            "Epoch 66/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.5768 - val_accuracy: 0.8226 - val_loss: 0.5863 - learning_rate: 0.0010\n",
            "Epoch 67/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.5522 - val_accuracy: 0.8197 - val_loss: 0.6028 - learning_rate: 0.0010\n",
            "Epoch 68/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.5577 - val_accuracy: 0.8264 - val_loss: 0.5273 - learning_rate: 0.0010\n",
            "Epoch 69/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7946 - loss: 0.5715 - val_accuracy: 0.8336 - val_loss: 0.5279 - learning_rate: 0.0010\n",
            "Epoch 70/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8007 - loss: 0.5843 - val_accuracy: 0.8193 - val_loss: 0.5592 - learning_rate: 0.0010\n",
            "Epoch 71/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.5517 - val_accuracy: 0.8364 - val_loss: 0.5236 - learning_rate: 0.0010\n",
            "Epoch 72/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8189 - loss: 0.5426 - val_accuracy: 0.8274 - val_loss: 0.5854 - learning_rate: 0.0010\n",
            "Epoch 73/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8195 - loss: 0.5437 - val_accuracy: 0.8398 - val_loss: 0.5291 - learning_rate: 5.0000e-04\n",
            "Epoch 74/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.5408 - val_accuracy: 0.8579 - val_loss: 0.4729 - learning_rate: 5.0000e-04\n",
            "Epoch 75/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.5256 - val_accuracy: 0.8402 - val_loss: 0.5060 - learning_rate: 5.0000e-04\n",
            "Epoch 76/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8243 - loss: 0.4926 - val_accuracy: 0.8531 - val_loss: 0.4907 - learning_rate: 5.0000e-04\n",
            "Epoch 77/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.4967 - val_accuracy: 0.8531 - val_loss: 0.4803 - learning_rate: 5.0000e-04\n",
            "Epoch 78/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.5308 - val_accuracy: 0.8565 - val_loss: 0.4805 - learning_rate: 5.0000e-04\n",
            "Epoch 79/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8224 - loss: 0.5032 - val_accuracy: 0.8441 - val_loss: 0.5103 - learning_rate: 5.0000e-04\n",
            "Epoch 80/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.5306 - val_accuracy: 0.8569 - val_loss: 0.4866 - learning_rate: 5.0000e-04\n",
            "Epoch 81/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8260 - loss: 0.4889 - val_accuracy: 0.8584 - val_loss: 0.4664 - learning_rate: 5.0000e-04\n",
            "Epoch 82/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.4935 - val_accuracy: 0.8560 - val_loss: 0.4886 - learning_rate: 5.0000e-04\n",
            "Epoch 83/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8289 - loss: 0.4898 - val_accuracy: 0.8493 - val_loss: 0.4954 - learning_rate: 5.0000e-04\n",
            "Epoch 84/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8238 - loss: 0.4821 - val_accuracy: 0.8588 - val_loss: 0.4839 - learning_rate: 5.0000e-04\n",
            "Epoch 85/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.5251 - val_accuracy: 0.8608 - val_loss: 0.5004 - learning_rate: 5.0000e-04\n",
            "Epoch 86/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8179 - loss: 0.5101 - val_accuracy: 0.8541 - val_loss: 0.4673 - learning_rate: 5.0000e-04\n",
            "Epoch 87/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8306 - loss: 0.4921 - val_accuracy: 0.8560 - val_loss: 0.4810 - learning_rate: 5.0000e-04\n",
            "Epoch 88/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8215 - loss: 0.5151 - val_accuracy: 0.8631 - val_loss: 0.4625 - learning_rate: 5.0000e-04\n",
            "Epoch 89/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8293 - loss: 0.4838 - val_accuracy: 0.8636 - val_loss: 0.4666 - learning_rate: 5.0000e-04\n",
            "Epoch 90/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8198 - loss: 0.4919 - val_accuracy: 0.8588 - val_loss: 0.4750 - learning_rate: 5.0000e-04\n",
            "Epoch 91/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.4894 - val_accuracy: 0.8526 - val_loss: 0.4826 - learning_rate: 5.0000e-04\n",
            "Epoch 92/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.4805 - val_accuracy: 0.8598 - val_loss: 0.4771 - learning_rate: 5.0000e-04\n",
            "Epoch 93/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8305 - loss: 0.4973 - val_accuracy: 0.8655 - val_loss: 0.4784 - learning_rate: 5.0000e-04\n",
            "Epoch 94/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 0.4927 - val_accuracy: 0.8574 - val_loss: 0.4763 - learning_rate: 5.0000e-04\n",
            "Epoch 95/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.4882 - val_accuracy: 0.8579 - val_loss: 0.4755 - learning_rate: 5.0000e-04\n",
            "Epoch 96/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8385 - loss: 0.4684 - val_accuracy: 0.8488 - val_loss: 0.4928 - learning_rate: 5.0000e-04\n",
            "Epoch 97/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.5382 - val_accuracy: 0.8622 - val_loss: 0.4507 - learning_rate: 5.0000e-04\n",
            "Epoch 98/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8275 - loss: 0.5036 - val_accuracy: 0.8603 - val_loss: 0.4595 - learning_rate: 5.0000e-04\n",
            "Epoch 99/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8395 - loss: 0.4852 - val_accuracy: 0.8650 - val_loss: 0.4612 - learning_rate: 5.0000e-04\n",
            "Epoch 100/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.4560 - val_accuracy: 0.8674 - val_loss: 0.4388 - learning_rate: 5.0000e-04\n",
            "Epoch 101/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8418 - loss: 0.4759 - val_accuracy: 0.8622 - val_loss: 0.4537 - learning_rate: 5.0000e-04\n",
            "Epoch 102/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8297 - loss: 0.4833 - val_accuracy: 0.8665 - val_loss: 0.4455 - learning_rate: 5.0000e-04\n",
            "Epoch 103/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8281 - loss: 0.4836 - val_accuracy: 0.8641 - val_loss: 0.4440 - learning_rate: 5.0000e-04\n",
            "Epoch 104/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.4983 - val_accuracy: 0.8655 - val_loss: 0.4564 - learning_rate: 5.0000e-04\n",
            "Epoch 105/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.4779 - val_accuracy: 0.8555 - val_loss: 0.4548 - learning_rate: 5.0000e-04\n",
            "Epoch 106/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.4734 - val_accuracy: 0.8631 - val_loss: 0.4647 - learning_rate: 5.0000e-04\n",
            "Epoch 107/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8470 - loss: 0.4519 - val_accuracy: 0.8603 - val_loss: 0.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 108/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8470 - loss: 0.4471 - val_accuracy: 0.8579 - val_loss: 0.4654 - learning_rate: 5.0000e-04\n",
            "Epoch 109/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8286 - loss: 0.4872 - val_accuracy: 0.8655 - val_loss: 0.4561 - learning_rate: 5.0000e-04\n",
            "Epoch 110/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8224 - loss: 0.5028 - val_accuracy: 0.8622 - val_loss: 0.4619 - learning_rate: 5.0000e-04\n",
            "Epoch 111/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 0.4625 - val_accuracy: 0.8746 - val_loss: 0.4283 - learning_rate: 2.5000e-04\n",
            "Epoch 112/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.4464 - val_accuracy: 0.8746 - val_loss: 0.4264 - learning_rate: 2.5000e-04\n",
            "Epoch 113/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8420 - loss: 0.4740 - val_accuracy: 0.8708 - val_loss: 0.4337 - learning_rate: 2.5000e-04\n",
            "Epoch 114/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8294 - loss: 0.4748 - val_accuracy: 0.8722 - val_loss: 0.4300 - learning_rate: 2.5000e-04\n",
            "Epoch 115/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.4788 - val_accuracy: 0.8727 - val_loss: 0.4357 - learning_rate: 2.5000e-04\n",
            "Epoch 116/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.4477 - val_accuracy: 0.8684 - val_loss: 0.4391 - learning_rate: 2.5000e-04\n",
            "Epoch 117/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8373 - loss: 0.4624 - val_accuracy: 0.8717 - val_loss: 0.4337 - learning_rate: 2.5000e-04\n",
            "Epoch 118/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8532 - loss: 0.4348 - val_accuracy: 0.8674 - val_loss: 0.4407 - learning_rate: 2.5000e-04\n",
            "Epoch 119/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.4316 - val_accuracy: 0.8698 - val_loss: 0.4314 - learning_rate: 2.5000e-04\n",
            "Epoch 120/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8514 - loss: 0.4197 - val_accuracy: 0.8746 - val_loss: 0.4301 - learning_rate: 2.5000e-04\n",
            "Epoch 121/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.4672 - val_accuracy: 0.8727 - val_loss: 0.4410 - learning_rate: 2.5000e-04\n",
            "Epoch 122/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8509 - loss: 0.4239 - val_accuracy: 0.8736 - val_loss: 0.4244 - learning_rate: 2.5000e-04\n",
            "Epoch 123/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.4246 - val_accuracy: 0.8755 - val_loss: 0.4183 - learning_rate: 2.5000e-04\n",
            "Epoch 124/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8466 - loss: 0.4380 - val_accuracy: 0.8712 - val_loss: 0.4383 - learning_rate: 2.5000e-04\n",
            "Epoch 125/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.4149 - val_accuracy: 0.8741 - val_loss: 0.4264 - learning_rate: 2.5000e-04\n",
            "Epoch 126/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 0.4374 - val_accuracy: 0.8698 - val_loss: 0.4297 - learning_rate: 2.5000e-04\n",
            "Epoch 127/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8489 - loss: 0.4315 - val_accuracy: 0.8751 - val_loss: 0.4244 - learning_rate: 2.5000e-04\n",
            "Epoch 128/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8590 - loss: 0.4010 - val_accuracy: 0.8684 - val_loss: 0.4373 - learning_rate: 2.5000e-04\n",
            "Epoch 129/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8388 - loss: 0.4596 - val_accuracy: 0.8751 - val_loss: 0.4163 - learning_rate: 2.5000e-04\n",
            "Epoch 130/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.4365 - val_accuracy: 0.8770 - val_loss: 0.4265 - learning_rate: 2.5000e-04\n",
            "Epoch 131/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8385 - loss: 0.4726 - val_accuracy: 0.8736 - val_loss: 0.4277 - learning_rate: 2.5000e-04\n",
            "Epoch 132/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.4513 - val_accuracy: 0.8732 - val_loss: 0.4298 - learning_rate: 2.5000e-04\n",
            "Epoch 133/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8422 - loss: 0.4546 - val_accuracy: 0.8727 - val_loss: 0.4266 - learning_rate: 2.5000e-04\n",
            "Epoch 134/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8572 - loss: 0.4405 - val_accuracy: 0.8803 - val_loss: 0.4183 - learning_rate: 2.5000e-04\n",
            "Epoch 135/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8482 - loss: 0.4440 - val_accuracy: 0.8689 - val_loss: 0.4431 - learning_rate: 2.5000e-04\n",
            "Epoch 136/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.4250 - val_accuracy: 0.8727 - val_loss: 0.4277 - learning_rate: 2.5000e-04\n",
            "Epoch 137/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 0.4339 - val_accuracy: 0.8746 - val_loss: 0.4194 - learning_rate: 2.5000e-04\n",
            "Epoch 138/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8370 - loss: 0.4573 - val_accuracy: 0.8727 - val_loss: 0.4237 - learning_rate: 2.5000e-04\n",
            "Epoch 139/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8513 - loss: 0.4330 - val_accuracy: 0.8746 - val_loss: 0.4308 - learning_rate: 2.5000e-04\n",
            "Epoch 140/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8413 - loss: 0.4451 - val_accuracy: 0.8774 - val_loss: 0.4234 - learning_rate: 1.2500e-04\n",
            "Epoch 141/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 0.4122 - val_accuracy: 0.8727 - val_loss: 0.4250 - learning_rate: 1.2500e-04\n",
            "Epoch 142/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8464 - loss: 0.4430 - val_accuracy: 0.8722 - val_loss: 0.4240 - learning_rate: 1.2500e-04\n",
            "Epoch 143/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8457 - loss: 0.4334 - val_accuracy: 0.8751 - val_loss: 0.4255 - learning_rate: 1.2500e-04\n",
            "Epoch 144/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 0.4162 - val_accuracy: 0.8722 - val_loss: 0.4108 - learning_rate: 1.2500e-04\n",
            "Epoch 145/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8487 - loss: 0.4415 - val_accuracy: 0.8751 - val_loss: 0.4215 - learning_rate: 1.2500e-04\n",
            "Epoch 146/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.4374 - val_accuracy: 0.8746 - val_loss: 0.4114 - learning_rate: 1.2500e-04\n",
            "Epoch 147/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.4373 - val_accuracy: 0.8732 - val_loss: 0.4177 - learning_rate: 1.2500e-04\n",
            "Epoch 148/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8521 - loss: 0.4286 - val_accuracy: 0.8774 - val_loss: 0.4184 - learning_rate: 1.2500e-04\n",
            "Epoch 149/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8541 - loss: 0.4205 - val_accuracy: 0.8746 - val_loss: 0.4240 - learning_rate: 1.2500e-04\n",
            "Epoch 150/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.4188 - val_accuracy: 0.8755 - val_loss: 0.4143 - learning_rate: 1.2500e-04\n",
            "Epoch 151/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.4407 - val_accuracy: 0.8770 - val_loss: 0.4203 - learning_rate: 1.2500e-04\n",
            "Epoch 152/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8481 - loss: 0.4460 - val_accuracy: 0.8732 - val_loss: 0.4248 - learning_rate: 1.2500e-04\n",
            "Epoch 153/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.4044 - val_accuracy: 0.8774 - val_loss: 0.4170 - learning_rate: 1.2500e-04\n",
            "Epoch 154/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.4338 - val_accuracy: 0.8755 - val_loss: 0.4141 - learning_rate: 1.2500e-04\n",
            "Epoch 155/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8537 - loss: 0.4175 - val_accuracy: 0.8784 - val_loss: 0.4141 - learning_rate: 6.2500e-05\n",
            "Epoch 156/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.4219 - val_accuracy: 0.8746 - val_loss: 0.4170 - learning_rate: 6.2500e-05\n",
            "Epoch 157/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 0.4138 - val_accuracy: 0.8798 - val_loss: 0.4124 - learning_rate: 6.2500e-05\n",
            "Epoch 158/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8479 - loss: 0.4249 - val_accuracy: 0.8774 - val_loss: 0.4102 - learning_rate: 6.2500e-05\n",
            "Epoch 159/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 0.4169 - val_accuracy: 0.8751 - val_loss: 0.4184 - learning_rate: 6.2500e-05\n",
            "Epoch 160/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 0.4047 - val_accuracy: 0.8794 - val_loss: 0.4139 - learning_rate: 6.2500e-05\n",
            "Epoch 161/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 0.4200 - val_accuracy: 0.8774 - val_loss: 0.4190 - learning_rate: 6.2500e-05\n",
            "Epoch 162/250\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8548 - loss: 0.4036 - val_accuracy: 0.8803 - val_loss: 0.4116 - learning_rate: 6.2500e-05\n",
            "Epoch 163/250\n",
            "\u001b[1m 11/306\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8286 - loss: 0.4307    "
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Enable mixed precision for faster GPU training\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Parameters\n",
        "sample_rate = 22050\n",
        "n_mels = 130\n",
        "hop_length = 512\n",
        "segment_length = 3  # 3-second clips\n",
        "n_frames = int((segment_length * sample_rate / hop_length) + 1)  # ~129 for 3 seconds\n",
        "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "batch_size = 16\n",
        "data_path = '/content/sample_data/data.json'  # Update with your GTZAN dataset path\n",
        "\n",
        "# Function to split audio into 3-second segments\n",
        "def split_audio(audio, sr, segment_length=3):\n",
        "    samples_per_segment = int(segment_length * sr)\n",
        "    segments = [audio[i:i + samples_per_segment] for i in range(0, len(audio), samples_per_segment)]\n",
        "    return segments\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading and preprocessing data...\")\n",
        "\n",
        "with open(data_path, \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "# Define X nd y\n",
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"genre_num\"])\n",
        "# Train-validation-test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
        "X_val = X_val[..., np.newaxis]      # Add channel dimension\n",
        "X_test = X_test[..., np.newaxis]    # Add channel dimension\n",
        "\n",
        "\n",
        "# Create tf.data datasets for efficient loading\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build simpler FCNN\n",
        "def build_fcnn(input_shape=(n_mels, n_frames, 1), num_classes=10):\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax', dtype='float32')  # Mixed precision output\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Build and compile model\n",
        "model = build_fcnn()\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),  # Default Adam LR\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train with early stopping\n",
        "# Step 6: Train model on T4 GPU\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
        "\n",
        "print(\"Training model...\")\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=250,\n",
        "    callbacks=[early_stopping,lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Plot training/validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5lAwurBUatqD",
      "metadata": {
        "id": "5lAwurBUatqD"
      },
      "outputs": [],
      "source": [
        "model.save('/content/sample_data/fcnn_splice_songs_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZFF4evN9api8",
      "metadata": {
        "id": "ZFF4evN9api8"
      },
      "source": [
        "## FCNN with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22STUyjhbek0",
      "metadata": {
        "id": "22STUyjhbek0"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import json\n",
        "\n",
        "# Enable mixed precision\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Parameters\n",
        "sample_rate = 22050\n",
        "n_mels = 130\n",
        "hop_length = 512\n",
        "segment_length = 3  # 3-second clips\n",
        "n_frames = int((segment_length * sample_rate / hop_length) + 1)  # ~129\n",
        "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "batch_size = 32  # Increased for GPU\n",
        "data_path = '/content/sample_data/data.json'  # Update with your GTZAN dataset path\n",
        "\n",
        "# Audio augmentations\n",
        "def augment_audio(audio, sr):\n",
        "    # Time-reversal (50% chance)\n",
        "    if np.random.rand() < 0.5:\n",
        "        audio = audio[::-1]\n",
        "    # Pitch shift (±2 semitones, 50% chance)\n",
        "    if np.random.rand() < 0.5:\n",
        "        n_steps = np.random.uniform(-2, 2)\n",
        "        audio = librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "    # Time stretch (0.8–1.2 rate, 50% chance)\n",
        "    if np.random.rand() < 0.5:\n",
        "        rate = np.random.uniform(0.8, 1.2)\n",
        "        audio = librosa.effects.time_stretch(audio, rate=rate)\n",
        "    return audio\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading and preprocessing data...\")\n",
        "\n",
        "with open(data_path, \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "# Define X nd y\n",
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"genre_num\"])\n",
        "\n",
        "# Train-validation-test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
        "X_val = X_val[..., np.newaxis]      # Add channel dimension\n",
        "X_test = X_test[..., np.newaxis]    # Add channel dimension\n",
        "\n",
        "# Create tf.data datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build FCNN\n",
        "def build_fcnn(input_shape=(n_mels, n_frames, 1), num_classes=10):\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax', dtype='float32')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Build and compile model\n",
        "model = build_fcnn()\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),  # Default Adam LR\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train with early stopping\n",
        "# Step 6: Train model on T4 GPU\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
        "# Train\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "print(\"Training model...\")\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=250,\n",
        "    callbacks=[early_stopping,lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Plot results\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
